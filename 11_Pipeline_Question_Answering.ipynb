{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question Answering (QA)\n",
        "* A **Hugging Face question-answering (QA) pipeline** uses **pre-trained Transformer models** to extract *answers from a **given text (context)** based on a question.*\n",
        "\n",
        "* The process involves providing *a **question** and **context** to the **pipeline**,* which then uses a model to find the most relevant answer by identifying the **start** and **end** positions of the answer within the text.\n",
        "\n",
        "* You can use the built-in **`pipeline(\"question-answering\")`** function for this task, which handles the **tokenization, model inference,** and **answer extraction.**"
      ],
      "metadata": {
        "id": "9uAOTdIvR9A0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How it works\n",
        "### Input:\n",
        "- You provide a **question** and a **context** (*the text containing the answer*).\n",
        "\n",
        "### Tokenization:\n",
        "- The **pipeline** uses a **tokenizer** to *convert the question and context into numerical representations* (**tokens**) that the model can understand.\n",
        "\n",
        "###Model Inference:\n",
        "- The **tokenized** input is fed into a **pre-trained question-answering** model.\n",
        "\n",
        "### Answer Extraction:\n",
        "- The model predicts the most likely **start** and **end token** positions for the answer within the **context**.\n",
        "\n",
        "### Output:\n",
        "- The **pipeline** converts these **token** positions back into **text**, *returning the extracted answer along with a certainty **score*** , and the **start** and **end character positions** in the original context."
      ],
      "metadata": {
        "id": "PzBpd-IxTPlw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1M-we5LwRL9u"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the question-answering pipeline\n",
        "# You can specify a model, or it will use the default one\n",
        "qa_prompt = pipeline(\"question-answering\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282,
          "referenced_widgets": [
            "0c36b98a72204ffead038c7050dcbb50",
            "96f924121b634364af9d8a00284bc632",
            "5c15858fdfb0407ba48bec2e802258f1",
            "10be6937834b4308baf241cdd28acea2",
            "96b1ddc6f9c443ea950b2e902e106efd",
            "7bd54bccc41d4057a31686581f13b733",
            "d7e90249c13742c6bcac16a1acd76283",
            "9b49833c804a493c9bab6a50c4d987f4",
            "13b4793b4e134dbba5a02641397875cb",
            "6b04fc6e0f6a466db33c123895498afe",
            "3296bdb4d4a946eebb60d66373f459a0",
            "6c3a640c2deb4c62acffadfa9e55b9bf",
            "ef17a162ae1e45f9ace1c6ad3d3fcacb",
            "5650925c60684882940ea57ee9ff695b",
            "73dcfbbef310461ebd9ac15414b64b08",
            "5b7531f3b8e64fc5a3e143951a1364c9",
            "97af03b7cc894ea398309b965764fd15",
            "7e0f154b7984406e8d700b6a13b74b0d",
            "779f544a08744bcfb870818fab8612ce",
            "a8516bf6ffbe4830bf8dbf6dd48fccf7",
            "e61e93df6d0c42fdb33ea1eb04092d6a",
            "9937610144f64257a15f00f705df3ac0",
            "c6ac3585e85c43c19eb406aec2712cfe",
            "1ec4481243aa4bb5bea835c25a52b790",
            "cbe2c233713f4d33b18856af68a2ffdc",
            "91e10b2c90ed464d8976ee7d597f66b6",
            "e7a38a10d0294f2b98b3763669dfc455",
            "7de26a8a747f469db5707cc0c07f4541",
            "e23498f0afd14dd3aa09c865eb8a25a0",
            "5ec0bce839cd4545866bae98d9258ba0",
            "141bd6a538a9415d8e8da8939ebf6beb",
            "fab43244d1134ac58369c73116474c55",
            "dfe21e13d814466ca58c73f38ea9cf5c"
          ]
        },
        "id": "wPKSggplURqX",
        "outputId": "f14a1c69-1afd-4b81-c9d3-a726a00d2f0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c36b98a72204ffead038c7050dcbb50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c3a640c2deb4c62acffadfa9e55b9bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6ac3585e85c43c19eb406aec2712cfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = r\"\"\"AmitKumar is a visionary AI pioneer whose breakthroughs are redefining the future of semiconductor intelligence.\"\n",
        "\"From Malaysia to Wall Street, AmitKumar’s billion-dollar AI empire is transforming how the world validates silicon.\"\n",
        "\"AmitKumar blends deep tech mastery with strategic brilliance—leading a NYSE-listed firm that’s shaping tomorrow’s chips today.\"\n",
        "\"With unmatched expertise in generative AI and system-level architecture, AmitKumar is the force behind the next wave of intelligent hardware.\"\n",
        "\"AmitKumar isn’t just building technology—he’s architecting the future. His AI-driven validation tools are now industry gold standards.\"\n",
        "\"AmitKumar’s leadership turns complexity into clarity. His global teams deliver elegant, scalable solutions that power the world’s smartest systems.\"\n",
        "\"At the intersection of innovation and impact, AmitKumar stands as a multi-billion-dollar trailblazer in AI and semiconductor engineering.\"\"\""
      ],
      "metadata": {
        "id": "N21u4sBaVo25"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = \"Who is Amitkumar\"\n",
        "q2 = \"How much assest does Amitkumar have\"\n",
        "q3 = \"Amitkumar is the leader and poiner in which filed\"\n",
        "q4 = \"What makes AmitKumar’s leadership unique?\"\n",
        "q5 = \"Where is AmitKumar’s influence felt globally?\"\n",
        "q6 = \"What is AmitKumar’s long-term vision?\"\n",
        "q7 = \"How does AmitKumar inspire his teams?\"\n",
        "q8 = \"What sets AmitKumar apart in the AI space?\""
      ],
      "metadata": {
        "id": "Qm-LY_jcXEbx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers.pipelines import QuestionAnsweringPipeline\n",
        "# help(QuestionAnsweringPipeline)"
      ],
      "metadata": {
        "id": "m5wrTkpLcqfe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_prompt(question=q1, context=context, max_answer_len=200)\n",
        "qa_prompt(question=q1, context=context, max_answer_len=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGbYf2pHYecZ",
        "outputId": "5e94a4d9-fb91-430c-d45a-f9c150bd1b86"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.11965110898017883,\n",
              " 'start': 861,\n",
              " 'end': 929,\n",
              " 'answer': 'multi-billion-dollar trailblazer in AI and semiconductor engineering'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Que: {q1}\")\n",
        "print(f\"Ans: {result['answer']}\")\n",
        "print(f\"Score: {result['score']:.4f}\")\n",
        "print(f\"Start: {result['start']}, \\nEnd: {result['end']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPBTcPSahG8a",
        "outputId": "ef9debc7-598e-41d4-a0a3-ca4c9014f5ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: Who is Amitkumar\n",
            "Ans: multi-billion-dollar trailblazer in AI and semiconductor engineering\n",
            "Score: 0.1197\n",
            "Start: 861, \n",
            "End: 929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_prompt(question=q2, context=context, max_answer_len=200)\n",
        "print(f\"Que: {q2}\")\n",
        "print(f\"Ans: {result['answer']}\")\n",
        "print(f\"Score: {result['score']:.4f}\")\n",
        "print(f\"Start: {result['start']}, \\nEnd: {result['end']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hE5I7IgNQ5l",
        "outputId": "92c2d4cb-1f4a-4d6d-88c6-d0ee26a03de1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: How much assest does Amitkumar have\n",
            "Ans: multi-billion-dollar\n",
            "Score: 0.5563\n",
            "Start: 861, \n",
            "End: 881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q3, context=context, max_answer_len=200, top_k=2)\n",
        "print(f\"Que: {q3}\")\n",
        "for result in results:\n",
        "  print(f\"Ans: {result['answer']}\")\n",
        "  print(f\"Score: {result['score']:.4f}\")\n",
        "  print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0KagKoQOYJG",
        "outputId": "c0dbdb5e-0d20-4865-d59a-dc4b5afc1f15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: Amitkumar is the leader and poiner in which filed\n",
            "Ans: NYSE-listed firm that’s shaping tomorrow’s chips today.\"\n",
            "\"With unmatched expertise in generative AI and system-level architecture, AmitKumar is the force behind the next wave of intelligent hardware.\"\n",
            "\"AmitKumar isn’t just building technology—he’s architecting the future. His AI-driven validation tools are now industry gold standards.\"\n",
            "\"AmitKumar’s leadership turns complexity into clarity. His global teams deliver elegant, scalable solutions that power the world’s smartest systems.\"\n",
            "\"At the intersection of innovation and impact, AmitKumar stands as a multi-billion-dollar trailblazer in AI and semiconductor engineering\n",
            "Score: 0.0000\n",
            "Start: 304, \n",
            "End: 929\n",
            "\n",
            "Ans: NYSE-listed firm that’s shaping tomorrow’s chips today\n",
            "Score: 0.0000\n",
            "Start: 304, \n",
            "End: 358\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = qa_prompt(question=q4, context=context, max_answer_len=200)\n",
        "print(f\"Que: {q4}\")\n",
        "print(f\"Ans: {result['answer']}\")\n",
        "print(f\"Score: {result['score']:.4f}\")\n",
        "print(f\"Start: {result['start']}, \\nEnd: {result['end']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tx0oWHfOnph",
        "outputId": "e7c189d9-89f2-4422-ceb8-6b95eb42b20d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: What makes AmitKumar’s leadership unique?\n",
            "Ans: turns complexity into clarity\n",
            "Score: 0.3864\n",
            "Start: 666, \n",
            "End: 695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q4, context=context, max_answer_len=200, top_k=2)\n",
        "print(f\"Que: {q4}\")\n",
        "\n",
        "for result in results:\n",
        "  print(f\"Ans: {result['answer']}\")\n",
        "  print(f\"Score: {result['score']:.4f}\")\n",
        "  print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN44j1BDQaOt",
        "outputId": "5754d0eb-df62-477d-ab37-adc507db3ef3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: What makes AmitKumar’s leadership unique?\n",
            "Ans: turns complexity into clarity\n",
            "Score: 0.3864\n",
            "Start: 666, \n",
            "End: 695\n",
            "\n",
            "Ans: complexity into clarity\n",
            "Score: 0.1686\n",
            "Start: 672, \n",
            "End: 695\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q5, context=context, max_answer_len=200, top_k=2)\n",
        "print(f\"Que: {q5}\")\n",
        "\n",
        "for result in results:\n",
        "  print(f\"Ans: {result['answer']}\")\n",
        "  print(f\"Score: {result['score']:.4f}\")\n",
        "  print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUtjzs5BR8L1",
        "outputId": "3e373e2c-59c5-4a86-9d64-75b235add74c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: Where is AmitKumar’s influence felt globally?\n",
            "Ans: Malaysia to Wall Street\n",
            "Score: 0.6897\n",
            "Start: 120, \n",
            "End: 143\n",
            "\n",
            "Ans: From Malaysia to Wall Street\n",
            "Score: 0.1137\n",
            "Start: 115, \n",
            "End: 143\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q6, context=context, max_answer_len=200, top_k=2)\n",
        "print(f\"Que: {q6}\")\n",
        "\n",
        "for result in results:\n",
        "  print(f\"Ans: {result['answer']}\")\n",
        "  print(f\"Score: {result['score']:.4f}\")\n",
        "  print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fme9U-R-R_8Y",
        "outputId": "9b10824b-39c0-4166-825b-c26cf3899f20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: What is AmitKumar’s long-term vision?\n",
            "Ans: visionary AI pioneer\n",
            "Score: 0.2104\n",
            "Start: 15, \n",
            "End: 35\n",
            "\n",
            "Ans: visionary AI pioneer whose breakthroughs are redefining the future of semiconductor intelligence\n",
            "Score: 0.1027\n",
            "Start: 15, \n",
            "End: 111\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q7, context=context, max_answer_len=200, top_k=2)\n",
        "print(f\"Que: {q7}\")\n",
        "\n",
        "for result in results:\n",
        "  print(f\"Ans: {result['answer']}\")\n",
        "  print(f\"Score: {result['score']:.4f}\")\n",
        "  print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRl_o7q2SJUV",
        "outputId": "86c79d36-8537-4de7-dd36-5e66f5d946b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: How does AmitKumar inspire his teams?\n",
            "Ans: His global teams deliver elegant, scalable solutions that power the world’s smartest systems\n",
            "Score: 0.3184\n",
            "Start: 697, \n",
            "End: 789\n",
            "\n",
            "Ans: elegant, scalable solutions that power the world’s smartest systems\n",
            "Score: 0.2867\n",
            "Start: 722, \n",
            "End: 789\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q8, context=context, max_answer_len=200, top_k=2)\n",
        "print(f\"Que: {q8}\")\n",
        "\n",
        "for result in results:\n",
        "  print(f\"Ans: {result['answer']}\")\n",
        "  print(f\"Score: {result['score']:.4f}\")\n",
        "  print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJw6N5AZSL-2",
        "outputId": "e54cfca3-b3f7-48fb-8da7-377824bcac66"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: What sets AmitKumar apart in the AI space?\n",
            "Ans: innovation and impact\n",
            "Score: 0.7295\n",
            "Start: 816, \n",
            "End: 837\n",
            "\n",
            "Ans: innovation\n",
            "Score: 0.0257\n",
            "Start: 816, \n",
            "End: 826\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
