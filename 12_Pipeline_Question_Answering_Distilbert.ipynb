{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Distilbert Base Cased Distilled Squad\n",
        "### Question answering\n",
        "- Meet **`DistilBERT Base Cased Distilled Squad`**, a powerful language model that's *smaller, faster, and more efficient* than its predecessors.\n",
        "- With **40%** fewer parameters than **BERT**, it runs **60%** faster while maintaining over **95%** of *BERT's performance.* This model is specifically designed for **`question-answering`** tasks and has been fine-tuned on the **SQuAD v1.1** dataset.\n",
        "\n",
        "  But what does this mean for you? It means you can get accurate answers quickly, without sacrificing performance. Whether you're working on a project that requires fast and reliable question-answering capabilities, or you're just curious about the potential of **AI**, **`DistilBERT Base Cased Distilled Squad`** is definitely worth exploring.\n",
        "  \n",
        "- So, what kind of questions can this model answer? It can handle a wide range of queries, from simple to complex, and provide relevant answers based on the context provided. But, as with any **AI model**, it's essential to be aware of its limitations and potential biases. The model's performance can be affected by the quality of the input data, and it may not always provide accurate or reliable answers. Nevertheless, **`DistilBERT Base Cased Distilled Squad`** is an impressive model that showcases the potential of **AI** in `**question-answering**` tasks.\n",
        "\n",
        "  Its efficiency, speed, and capabilities make it an excellent choice for various applications, from chatbots to virtual assistants."
      ],
      "metadata": {
        "id": "LCKYNK1XWP07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mtevpWXjlR-R"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"distilbert-base-cased-distilled-squad\", max_seq_len=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "9d1ea79eae7243f7a10876dc9fd3eb2e",
            "8bc9b8a8070f4cfb9031f09608dd2ca7",
            "adb366bdb6414c719863372078de10ed",
            "327d97a1a1a844bc9d8e81d15d6a987b",
            "dcddcad6c5f14ac881d0a63692302a5e",
            "076ffd0f0daf44759c85ae1aa08e7278",
            "e9816fbc7bdf4a66b14297c1a6470f04",
            "a679188414bb460f8dde1d5aedcf5aa8",
            "e763a1f8a7654ea4aea92ffc612a92ae",
            "1a119616e66c459db854b100917d9d5e",
            "7ef6775c7d634d34a23dfcdfe90c9264",
            "ad873ea1b1da4c0bb4f05ed0b29b1658",
            "fc377061953a4ea6bcb95f2db90d473e",
            "1dd1aa347c0b48f991fc444c2d82f70d",
            "b3342d1ba54e454a89512bbf84df9073",
            "f529664672994234b7d7827114e9bfc6",
            "29ff92486d8b4b4a85d9d908942659c0",
            "8dbfafa8ca3043acbaa0be6e6dd46fcf",
            "2df2fd02b997414ca185ec3a8d12a5c2",
            "521d1e216b9644cc875857f3ea4ac71c",
            "94d28993d5f84760b6e993e27f791542",
            "138d5e48770046f3b20413ddf803ed19",
            "0381d0626fbe4948985cc77bdbb40713",
            "2e8ba59acb084eaeb6b9029650568bdd",
            "85aa9188495b4163bdd315830fd2d411",
            "7b511741f7a3495a84c63cd80bdc32c9",
            "2854d9397eef4d48a9e2fe33e2f8d90d",
            "c04d5cebec714b6e80ceb4c230eea500",
            "93ab1062821943e39b4087de4aa13a86",
            "8d7d34bc8b274571b483fe8b0ab84717",
            "6bbba7348e9d42bc9e9571dd69ddca0a",
            "8c64b017f279463fa62da2585dc6cdf0",
            "f0a953c952e649f3aecd79c9012d96ca"
          ]
        },
        "id": "rg9DLjFmmJ0a",
        "outputId": "eefc1a05-864f-45b3-84fa-30d7fdcbab1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d1ea79eae7243f7a10876dc9fd3eb2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad873ea1b1da4c0bb4f05ed0b29b1658"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 0 files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0381d0626fbe4948985cc77bdbb40713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = r\"\"\"AmitKumar is a visionary AI pioneer whose breakthroughs are redefining the future of semiconductor intelligence.\"\n",
        "\"From Malaysia to Wall Street, AmitKumar’s billion-dollar AI empire is transforming how the world validates silicon.\"\n",
        "\"AmitKumar blends deep tech mastery with strategic brilliance—leading a NYSE-listed firm that’s shaping tomorrow’s chips today.\"\n",
        "\"With unmatched expertise in generative AI and system-level architecture, AmitKumar is the force behind the next wave of intelligent hardware.\"\n",
        "\"AmitKumar isn’t just building technology—he’s architecting the future. His AI-driven validation tools are now industry gold standards.\"\n",
        "\"AmitKumar’s leadership turns complexity into clarity. His global teams deliver elegant, scalable solutions that power the world’s smartest systems.\"\n",
        "\"At the intersection of innovation and impact, AmitKumar stands as a multi-billion-dollar trailblazer in AI and semiconductor engineering.\"\"\""
      ],
      "metadata": {
        "id": "L0Hcgm3JmzSN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q1 = \"Who is Amitkumar\"\n",
        "q2 = \"How much assest does Amitkumar have\"\n",
        "q3 = \"Amitkumar is the leader and pioneer in which filed\"\n",
        "q4 = \"What makes Amitkumar’s leadership unique?\"\n",
        "q5 = \"Where is Amitkumar’s influence felt globally?\"\n",
        "q6 = \"What is Amitkumar’s long-term vision?\"\n",
        "q7 = \"How does Amitkumar inspire his teams?\"\n",
        "q8 = \"What sets Amitkumar apart in the AI space?\""
      ],
      "metadata": {
        "id": "u3BmyAR6nPxM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_prompt(question=q1, context=context, max_answer_len=512, top_k=2)\n",
        "\n",
        "print(f\"Que: {q3}\")\n",
        "\n",
        "for result in results:\n",
        "    print(f\"Ans: {result['answer']}\")\n",
        "    print(f\"Score: {round(result['score'], 4)}\")\n",
        "    print(f\"Start: {result['start']}, \\nEnd: {result['end']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIEw6DmGXxEa",
        "outputId": "16b49f2d-2c0a-4560-9d6e-98ef7edee4a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Que: Amitkumar is the leader and pioneer in which filed\n",
            "Ans: multi-billion-dollar trailblazer in AI and semiconductor engineering\n",
            "Score: 0.1197\n",
            "Start: 861, \n",
            "End: 929\n",
            "\n",
            "Ans: a visionary AI pioneer whose breakthroughs are redefining the future of semiconductor intelligence.\"\n",
            "\"From Malaysia to Wall Street, AmitKumar’s billion-dollar AI empire is transforming how the world validates silicon.\"\n",
            "\"AmitKumar blends deep tech mastery with strategic brilliance—leading a NYSE-listed firm that’s shaping tomorrow’s chips today.\"\n",
            "\"With unmatched expertise in generative AI and system-level architecture, AmitKumar is the force behind the next wave of intelligent hardware.\"\n",
            "\"AmitKumar isn’t just building technology—he’s architecting the future. His AI-driven validation tools are now industry gold standards.\"\n",
            "\"AmitKumar’s leadership turns complexity into clarity. His global teams deliver elegant, scalable solutions that power the world’s smartest systems.\"\n",
            "\"At the intersection of innovation and impact, AmitKumar stands as a multi-billion-dollar trailblazer in AI and semiconductor engineering\n",
            "Score: 0.1082\n",
            "Start: 13, \n",
            "End: 929\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_prompt(question=q1, context=context, max_answer_len=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIS-MwNjoLeV",
        "outputId": "09a7969f-053a-4709-82e7-fb2b46b47f21"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.11965110898017883,\n",
              " 'start': 861,\n",
              " 'end': 929,\n",
              " 'answer': 'multi-billion-dollar trailblazer in AI and semiconductor engineering'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In the output of a **`question-answering` pipeline** from the **transformers** library, the **score** represents the *model's confidence or probability* that the returned answer is **correct**.\n",
        "* The **score** is a *floating-point number* between **0 and 1.**\n",
        "\n",
        "### How to interpret the score\n",
        "- **A high score (close to 1.0)** indicates that the model is *very confident in its prediction.* For example, a **score of 0.98** suggests that the model is **98% confident** that the provided answer is the correct span of text.\n",
        "\n",
        "- **A low score (close to 0.0)** indicates that the model has *low confidence in its prediction.* This may happen if the answer is difficult to find in the provided text or if the model isn't certain about the **correct starting** and **ending points** for the answer.\n",
        "\n",
        "- **The score is relative,** not absolute. You should not treat the **score** as a guarantee of correctness, but rather as a way to rank different possible answers. If you retrieve multiple possible answers by setting the **`top_k`** parameter in the **pipeline**, *the answers will be sorted by their **scores**.*"
      ],
      "metadata": {
        "id": "p5EFms8rURFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "question_tokens = tokenizer(q8, truncation=True, max_length=64, return_tensors=\"pt\")\n",
        "\n",
        "qa_prompt(question=q8, context=context, max_answer_len=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikt2aYO6oeYT",
        "outputId": "600d1907-290d-45e5-e7a7-50001938c662"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9228577613830566,\n",
              " 'start': 816,\n",
              " 'end': 837,\n",
              " 'answer': 'innovation and impact'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "inputs = tokenizer(q1, context, max_length=512, truncation=True, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "outputs"
      ],
      "metadata": {
        "id": "RNFs8hdSptRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7358352b-a139-43ca-8ee2-7242e47bcf31"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ -1.2389,  -6.2129,  -8.3533,  -0.9911,  -8.7075,  -7.4634,  -8.5765,\n",
              "          -1.9252,  -9.1190,  -8.9721,  -8.7913,  -9.9216,  -6.2791,   0.4808,\n",
              "          -1.3839,  -8.2851,  -2.2033,  -4.8975,  -5.5442,  -5.6380,  -8.8546,\n",
              "          -9.2331,  -6.9678,  -9.4711,  -9.2200,  -7.8316,  -6.6761,  -9.9509,\n",
              "          -7.0657, -10.1199,  -7.3422,  -9.0427,  -7.5630,  -6.8769,  -5.4482,\n",
              "          -5.1631, -10.3367,  -7.7392,  -8.9482,  -8.9671,  -3.9104,  -9.6928,\n",
              "          -8.8810,  -9.4644,  -9.7066,  -7.7600,  -7.8002,  -5.1718,  -9.6468,\n",
              "          -8.7730,  -5.4719,  -8.4407, -10.0306,  -7.2098,  -8.9859,  -8.8216,\n",
              "          -9.2875,  -8.8691, -11.0837,  -6.2592,  -8.6971,  -7.6007,  -6.4259,\n",
              "          -4.1075, -10.2432,  -9.5142,  -9.6601,  -9.8317,  -7.9307, -10.3931,\n",
              "          -7.5790,  -9.5624,  -9.8372, -10.7527, -11.1586,  -7.3657,  -9.4436,\n",
              "         -11.1491,  -9.6949,  -9.4182,  -5.5680,  -5.4111,  -5.4444, -10.1174,\n",
              "          -9.7615,  -7.8623,  -7.6694,  -8.9352,  -9.1161, -10.0102,  -7.8587,\n",
              "          -7.5501, -10.0564, -10.4384,  -7.9237,  -8.2742,  -9.3302,  -8.5465,\n",
              "          -6.0139,  -5.9491,  -6.2732,  -9.8019,  -9.4098,  -7.1890, -10.2915,\n",
              "          -7.6031, -10.7252,  -8.4085, -10.7021,  -7.3433, -10.7958,  -9.8196,\n",
              "          -7.7552,  -8.3594,  -3.0699,  -9.8890,  -9.5029,  -9.6512, -10.3313,\n",
              "          -8.1547,  -5.8244,  -6.3975,  -8.7412,  -7.9862,  -7.4233,  -8.5392,\n",
              "         -10.6090,  -6.5979,  -7.1300,  -9.2172,  -8.1151,  -5.1717,  -2.3346,\n",
              "          -9.8297,  -9.1769,  -9.7392, -10.2346,  -6.4573,  -8.0550,  -6.6261,\n",
              "          -7.0426,  -5.0567,  -7.0551,  -9.4080,  -3.8039,  -8.5977,  -9.2200,\n",
              "          -5.1365,  -9.6012,  -8.0510,  -6.1172,  -9.0842,  -5.7582,  -6.3779,\n",
              "         -10.5612,  -9.0061,  -7.8171, -11.0448,  -9.5747,  -9.9713,  -7.8170,\n",
              "          -6.7403,  -8.4243,  -9.1336,  -9.5624,  -8.5569,  -7.4720,  -4.6406,\n",
              "         -10.0047,  -9.7174,  -9.8204, -10.5052,  -8.9024,  -9.0939,  -7.5328,\n",
              "          -9.5860,  -8.8740, -11.2406,  -8.3650, -10.0599,  -4.9360,  -5.5174,\n",
              "          -7.7717,  -8.9254,  -6.7304,  -9.5323,  -7.7549, -10.2640, -10.0567,\n",
              "          -7.5936, -10.1890,  -9.1292,  -9.7539,  -9.3481, -10.3746, -10.7067,\n",
              "          -8.6983, -10.9003,  -9.0022,  -9.0687,  -8.7483,  -3.4220,  -2.1441,\n",
              "          -6.4323,  -6.1637,  -9.7665,  -5.7896,  -9.6702,  -7.1515,  -6.0251,\n",
              "           0.0300,  -8.7449,  -8.2869,  -8.2973,  -9.0143,  -3.5151,  -3.0247,\n",
              "           0.3204,   0.5818,  -7.6124,  -5.7945,  -7.7535,  -5.3865,  -2.6569,\n",
              "          -7.7272,  -6.7123,  -7.6020,  -4.0515,  -8.5093,  -5.4042,  -9.0349,\n",
              "          -4.5236,  -6.2523,  -8.5765]], grad_fn=<CloneBackward0>), end_logits=tensor([[ -0.8320,  -6.3393,  -8.3803,  -8.2183,  -7.8561,  -4.5098,  -8.8982,\n",
              "          -8.8977,  -8.6390,  -9.0785,  -8.3671,  -3.0330,  -8.3320,  -7.2738,\n",
              "          -8.2693,  -4.8174,  -2.4897,   0.7931,  -6.7299,  -8.5222,  -7.5279,\n",
              "          -9.2866,  -9.5031,  -9.0154,  -7.8712,  -9.8207,  -6.8681,  -9.8442,\n",
              "          -9.8487,  -7.3262,  -1.9153,  -3.2946,  -4.5244,  -8.1233,  -9.3775,\n",
              "          -5.5020, -10.4639,  -9.1072,  -4.7407,  -6.7759,  -9.8780,  -9.3941,\n",
              "          -9.4963,  -9.3242,  -5.3036,  -8.1580,  -7.2846,  -8.1899,  -9.2575,\n",
              "          -6.9879,  -6.3361,  -6.8024, -10.2382,  -8.0411, -10.1672, -10.8380,\n",
              "          -8.8165, -10.3999,  -9.2330,  -4.0793,  -4.4206,  -5.0301,  -8.2285,\n",
              "          -9.8604,  -9.9083, -10.0543,  -9.6510,  -6.8487, -10.6488, -10.0379,\n",
              "         -10.2120,  -8.5092,  -9.7757,  -7.3247, -10.8002,  -9.2460, -10.2633,\n",
              "         -10.0539,  -4.8129,  -6.3155,  -9.0205,  -9.3594,  -8.7284,  -6.7586,\n",
              "          -8.8297,  -6.8415,  -5.6397,  -9.0051,  -9.5471,  -9.5354,  -8.9398,\n",
              "          -8.8409,  -9.2634,  -8.8873,  -6.0998,  -3.6816,  -5.0056,  -5.5767,\n",
              "          -7.6053, -10.0489, -10.1699, -10.7399,  -8.7024,  -7.2428, -10.0716,\n",
              "         -10.4021,  -8.5129,  -5.5838, -10.2644,  -8.9231,  -9.7795,  -8.7009,\n",
              "          -3.2820,  -5.9185,  -9.8136,  -9.5692,  -9.9492,  -9.4137,  -5.5181,\n",
              "         -10.5596, -10.3166,  -7.6855,  -9.5229, -10.4104,  -9.3674,  -7.5160,\n",
              "         -10.3974,  -8.9230,  -2.1460,  -4.1469,  -4.6104,  -8.6094,  -9.7066,\n",
              "          -9.8516, -10.1893,  -9.7781,  -6.2045, -10.6498, -10.1445,  -9.7539,\n",
              "         -10.1874,  -8.5054,  -2.4286,  -7.1277,  -8.9676, -10.3641, -10.4186,\n",
              "          -8.8982,  -8.7993, -10.2600,  -2.4186,  -4.4804,  -9.2939,  -8.5399,\n",
              "         -10.2162,  -8.2108, -10.1834,  -8.6125,  -7.2090, -10.2268,  -9.3775,\n",
              "          -9.2780,  -7.6015,  -3.7068,  -5.1264,  -4.8077,  -9.0021, -10.3967,\n",
              "          -9.6987, -10.2734,  -9.6780,  -6.4237,  -9.6107,  -9.1654,  -9.1472,\n",
              "         -11.3011,  -7.9755, -10.9026,  -5.6933,  -7.1853,  -8.9453,  -8.2044,\n",
              "          -6.6085,  -9.8006,  -7.9625,  -8.4918, -10.6057, -10.2443,  -8.7267,\n",
              "          -6.2510, -10.0895,  -9.8466, -10.6925,  -9.3619,  -9.6634,  -9.4409,\n",
              "          -9.4482,  -8.6668,  -4.0550,  -3.9818,  -4.5214,  -4.9871,  -8.3570,\n",
              "          -9.7591,  -7.6289,  -9.7743,  -6.0280,  -9.3102,  -1.3503,  -3.5690,\n",
              "          -8.7019,  -8.7213,  -9.0692,  -8.4881,  -3.7041,  -6.4618,  -7.7994,\n",
              "          -6.6217,  -6.0449,  -7.5258,  -5.6161,  -6.7758,  -1.4472,  -6.3142,\n",
              "          -7.2352,   1.1960,  -6.7373,  -4.6640,  -7.8500,  -9.0362,  -5.6870,\n",
              "           2.3614,   1.2764,  -8.8981]], grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}
