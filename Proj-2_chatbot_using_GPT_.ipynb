{"cells":[{"cell_type":"markdown","metadata":{"id":"i2yrutAQ3JNE"},"source":["# [Training your own Chatbot using GPT​](https://www.youtube.com/watch?v=DxygPxcfW_I)"]},{"cell_type":"markdown","metadata":{"id":"WwyFBkGt44rE"},"source":["# [Transformers](https://pypi.org/project/transformers/)\n","**Transformers** provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio.\n","\n","These models can be applied on:\n","\n","📝 **Text**, for tasks like text classification, information extraction, question answering, summarization, translation, and text generation, in over 100 languages.\n","\n","🖼️ **Images**, for tasks like image classification, object detection, and segmentation.\n","\n","🗣️ **Audio**, for tasks like speech recognition and audio classification."]},{"cell_type":"markdown","source":["ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"],"metadata":{"id":"yQWTcD0_VTFJ"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104121,"status":"ok","timestamp":1716469716656,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"nKPiZcDY2-lJ","outputId":"928159b7-d83c-49e8-e6eb-7ddaadf7a29b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)\n","Collecting accelerate>=0.21.0 (from transformers[torch])\n","  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[torch]) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n","Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"]}],"source":["!pip install transformers\n","!pip install transformers[torch]"]},{"cell_type":"markdown","metadata":{"id":"JSYt1nqV7gQM"},"source":["# [torch 2.3.0](https://pypi.org/project/torch/)\n","**PyTorch** is a Python package that provides two high-level features:\n","\n","* Tensor computation (like NumPy) with strong GPU acceleration\n","* Deep neural networks built on a tape-based autograd system"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11219,"status":"ok","timestamp":1716469727868,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"HFzcRqLM7Tu3","outputId":"b7f3dc44-875c-4950-ee6a-4f931b1664d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch"]},{"cell_type":"markdown","metadata":{"id":"91OdOX1x9mGs"},"source":["# [python-docx](https://pypi.org/project/python-docx/)\n","**python-docx** is a Python library for reading, creating, and updating Microsoft Word 2007+ (.docx) files."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12013,"status":"ok","timestamp":1716469739852,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"6x_Uycfc9w90","outputId":"bce7dd25-9104-4565-b4ba-0d7a44468ae2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-docx\n","  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m184.3/244.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n","Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.11.0)\n","Installing collected packages: python-docx\n","Successfully installed python-docx-1.1.2\n"]}],"source":["!pip install python-docx"]},{"cell_type":"markdown","metadata":{"id":"bUyBqrTY-Ck8"},"source":["# [PyPDF2](https://pypi.org/project/PyPDF2/)\n","**PyPDF2** is a free and open-source pure-python PDF library capable of splitting, merging, cropping, and transforming the pages of PDF files. It can also add custom data, viewing options, and passwords to PDF files. PyPDF2 can retrieve text and metadata from PDFs as well."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9648,"status":"ok","timestamp":1716469749478,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"FHaBSrjv-tOm","outputId":"9cf12d38-dc31-4a9b-caba-d7d65656f428"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m194.6/232.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2\n","Successfully installed PyPDF2-3.0.1\n"]}],"source":["!pip install -U PyPDF2"]},{"cell_type":"markdown","metadata":{"id":"VSWHBJ5D1OHb"},"source":["### Import general required libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"uLaJHtS41Qcy","executionInfo":{"status":"ok","timestamp":1716469754488,"user_tz":-480,"elapsed":5034,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["import os\n","import re\n","from PyPDF2 import PdfReader\n","import docx\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"pzWbOnL2DbGc"},"source":["# All the below classes are provided by the \"Hugging Face\" Transformers library."]},{"cell_type":"markdown","metadata":{"id":"BLZOUWbr3Qf-"},"source":["## [class transformers.GPT2Tokenizer](https://huggingface.co/docs/transformers/en/model_doc/gpt2#transformers.GPT2Tokenizer)\n","* The `GPT2Tokenizer` class is used for tokenizing text data in a way that is compatible with the GPT-2 model.\n","* Tokenization involves converting a string of text into a list of tokens (words or subwords) that can be processed by the model.\n","* This step is crucial for preparing text data for tasks such as text generation, text completion, or any other NLP application involving GPT-2."]},{"cell_type":"markdown","metadata":{"id":"aJohBOYd4uOB"},"source":["## [class transformers.GPT2LMHeadModel](https://huggingface.co/docs/transformers/en/model_doc/gpt2#transformers.GPT2LMHeadModel)\n","\n","`GPT2LMHeadModel` stands for \"Language Modeling Head.\" This model includes a language modeling head on top of the GPT-2 architecture, which is specifically designed for generating text. It predicts the next token in a sequence, making it suitable for tasks like text completion, text generation, and other sequence prediction tasks."]},{"cell_type":"markdown","metadata":{"id":"GjbM9gvk_q02"},"source":["## TextDataset\n","The `TextDataset` class helps in loading and processing text data in a format suitable for training and evaluation with transformer models.\n","\n","1. **Tokenization**: Automatically tokenizes the input text using a specified tokenizer.\n","2. **Encoding**: Converts the tokenized text into numerical format that models can process.\n","3. **Handling Large Datasets**: Efficiently handles large text files by loading data in chunks.\n"]},{"cell_type":"markdown","metadata":{"id":"k0MUrl_8Asnd"},"source":["## [class transformers.DataCollatorForLanguageModeling](https://huggingface.co/docs/transformers/v4.41.0/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling)\n","\n","This collator handles the batching and padding of sequences to ensure that all input sequences in a batch have the same length, which is necessary for efficient GPU utilization.\n","\n","It can be used for both <u>causal language modeling</u> (**CLM**) and <u>masked language modeling</u> (**MLM**) tasks, depending on the configuration."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"S5wvnlT31TRs","executionInfo":{"status":"ok","timestamp":1716469771415,"user_tz":-480,"elapsed":16932,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling"]},{"cell_type":"markdown","metadata":{"id":"F6XgvszDH7xW"},"source":["## [class transformers.Trainer](https://huggingface.co/docs/transformers/v4.41.0/en/main_classes/trainer#transformers.Trainer)\n","\n","It is a high-level API that simplifies the process of training and evaluating transformer models. It provides a flexible and easy-to-use interface for fine-tuning and training models on custom datasets.\n","\n","Few key features:-\n","1. **Fine-Tuning Pre-Trained Models**:\n","   - **Quick Fine-Tuning**: Easily fine-tune pre-trained models (like BERT, GPT-2, RoBERTa) on your custom datasets for specific tasks such as text classification, named entity recognition, or text generation.\n","\n","2. **Evaluation and Metrics**:\n","   - **Built-in Evaluation**: Automatically handles evaluation during and after training, providing metrics such as accuracy, precision, recall, and F1 score.\n","   - **Custom Metrics**: Allows users to define and use custom evaluation metrics.\n","\n","3. **Distributed Training**:\n","   - **Multi-GPU Training**: Supports training across multiple GPUs to accelerate the process.\n","   - **Distributed Training**: Can handle training on multiple nodes in a distributed setting, making it suitable for large-scale training.\n"]},{"cell_type":"markdown","metadata":{"id":"jE58GoZSJl1s"},"source":["## [class transformers.TrainingArguments](https://huggingface.co/docs/transformers/v4.41.0/en/main_classes/trainer#transformers.TrainingArguments)\n","\n","The `TrainingArguments` class is used to define the training configuration and hyperparameters for training Transformer-based models.\n","\n","By importing `TrainingArguments`, you gain access to a class that lets you specify various parameters such as the number of epochs, learning rate, batch size, evaluation strategy, logging options, and more, which are crucial for training machine learning models effectively.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7mlA1eRNJM49","executionInfo":{"status":"ok","timestamp":1716469772348,"user_tz":-480,"elapsed":955,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["from transformers import Trainer, TrainingArguments"]},{"cell_type":"markdown","metadata":{"id":"kU430dos1W6K"},"source":["# <font color='red'>Caution: Use only single GPT model at a time.</font>"]},{"cell_type":"markdown","metadata":{"id":"tMdLulg2CHik"},"source":["# [GPT-2](https://huggingface.co/openai-community/gpt2)\n","Pretrained model on English language using a <u>causal language modeling (CLM)</u> objective.\n","\n","## Model description\n","**GPT-2** is a transformers model pretrained on a very large corpus of English data in a self-supervised fashion. This means it was pretrained on the raw texts only, with no humans labelling them in any way (which is why it can use lots of publicly available data) with an automatic process to generate inputs and labels from those texts. More precisely, it was trained to guess the next word in sentences.\n","\n","This is the <u>**smallest** version of GPT-2, with **124M**</u> parameters."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1716469772349,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"zECNSKv4B3Y0","outputId":"919fe22c-a677-4f00-ecbe-9f6fbf89f8b7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Use a pipeline as a high-level helper\\nfrom transformers import pipeline\\n\\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["'''\n","# Use a pipeline as a high-level helper\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n","'''"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1716469772349,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"mbENcHkjB5q8","outputId":"e6c8af99-3d8e-4a56-e72f-cf592b020544"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Load model directly\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\\n\\ntokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\\nmodel = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["'''\n","# Load model directly\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n","model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n","'''"]},{"cell_type":"markdown","metadata":{"id":"A3OQnpeF2Dp_"},"source":["# [GPT-2 Medium](https://huggingface.co/openai-community/gpt2-medium)\n","## Model Description\n","**GPT-2 Medium** is the **355M** parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a <u>causal language modeling (CLM)</u> objective."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1716469772351,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"xrh49HH93-dv","outputId":"060c280d-dc84-4efb-d1e3-8e63e533f20a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Use a pipeline as a high-level helper\\nfrom transformers import pipeline\\n\\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2-medium\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["'''\n","# Use a pipeline as a high-level helper\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2-medium\")\n","'''"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1716469772351,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"E_TxAygT4FQH","outputId":"614f52df-cf4b-4d64-8ba3-5785327aec1a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Load model directly\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\\n\\ntokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-xl\")\\nmodel = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-xl\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["'''\n","# Load model directly\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-xl\")\n","model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-xl\")\n","'''"]},{"cell_type":"markdown","metadata":{"id":"PU0LViDh1hTV"},"source":["# [GPT-2 Large](https://huggingface.co/openai-community/gpt2-large)\n","## Model Description\n","**GPT-2 Large** is the **774M** parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a <u>causal language modeling (CLM)</u> objective."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1716469772352,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"Z827LJt-2DQC","outputId":"f803f8cf-b451-4aca-bbb4-3bf53deab0b8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Use a pipeline as a high-level helper\\nfrom transformers import pipeline\\n\\npipe = pipeline(\"text-generation\", model=\"openai-community/gpt2-large\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["'''\n","# Use a pipeline as a high-level helper\n","from transformers import pipeline\n","\n","pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2-large\")\n","'''"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":796,"status":"ok","timestamp":1716469773123,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"n2_T2act2KXZ","outputId":"d903ac0a-2de0-4bf9-f96a-c7be632594c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# Load model directly\\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\\n\\ntokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-large\")\\nmodel = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-large\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}],"source":["'''\n","# Load model directly\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-large\")\n","model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-large\")\n","'''"]},{"cell_type":"markdown","metadata":{"id":"YPrzMfl10xtH"},"source":["# [GPT-2 XL](https://huggingface.co/openai-community/gpt2-xl)\n","## Model Description\n","**GPT-2 XL** is the **1.5B** parameter version of GPT-2, a transformer-based language model created and released by OpenAI. The model is a pretrained model on English language using a <u>causal language modeling (CLM)</u> objective."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1716469773124,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"},"user_tz":-480},"id":"90zZuz-B0Odx","outputId":"1c145b06-4243-43b2-8b6b-ee512f1fd901"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfrom transformers import pipeline, set_seed\\ngenerator = pipeline(\\'text-generation\\', model=\\'gpt2-xl\\')\\nset_seed(42)\\ngenerator(\"Hello, I\\'m a language model,\", max_length=30, num_return_sequences=5)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["'''\n","from transformers import pipeline, set_seed\n","generator = pipeline('text-generation', model='gpt2-xl')\n","set_seed(42)\n","generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"1ERPpNAvaJ0f"},"source":["# Functions required to read different types of files.\n","## These files can be a mix of *.pdf, *.docx ot *.txt"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"CXD-ztg5X8TY","executionInfo":{"status":"ok","timestamp":1716469773125,"user_tz":-480,"elapsed":19,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["# read any number of pdf documents from the directory path and stored as a text file.\n","def read_pdf(file_path):\n","  with open(file_path, 'rb') as file:\n","    pdf_reader = PdfReader(file)\n","    text = \"\"\n","    for page_num in range(len(pdf_reader.pages)):\n","      text += pdf_reader.pages[page_num].extract_text()\n","  return text"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"7ktjRIwsaMaR","executionInfo":{"status":"ok","timestamp":1716469773126,"user_tz":-480,"elapsed":19,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["# read any number of word documents from the directory path and stored as a text file.\n","def read_word(file_path):\n","  doc = docx.Document(file_path)\n","  text = \"\"\n","  for paragraph in doc.paragraphs:\n","    text += paragraph.text + \"\\n\"\n","  return text"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"tjl-e_32bfnM","executionInfo":{"status":"ok","timestamp":1716469773126,"user_tz":-480,"elapsed":19,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["# read any number of text documents from the directory path and stored as a text file.\n","def read_text(file_path):\n","  with open(file_path, 'r') as file:\n","    text = file.read()\n","  return text"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"wT_0Yz7kXIFi","executionInfo":{"status":"ok","timestamp":1716469773127,"user_tz":-480,"elapsed":20,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["# read all types of and any number of documents from the directory path and stored as text file.\n","def read_documents_from_directory(directory):\n","  combined_text = \"\"\n","  for filename in os.listdir(directory):\n","    file_path = os.path.join(directory, filename)\n","\n","    if filename.endswith(\".pdf\"):\n","      combined_text += read_pdf(file_path)\n","    elif filename.endswith(\".docx\"):\n","      combined_text += read_word(file_path)\n","    elif filename.endswith(\".txt\"):\n","      combined_text += read_text(file_path)\n","  return combined_text"]},{"cell_type":"markdown","metadata":{"id":"wMh2xql_bpaT"},"source":["## Train a chatbot\n","### Here, the \"train_chatbot\" function uses the **combined_text** data to train a GPT-2 model using the provided training arguments. The resulting trained model and tokenizer are then saved to a specified output directory as mentioned in the program."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"4bkisKSNbstf","executionInfo":{"status":"ok","timestamp":1716469773127,"user_tz":-480,"elapsed":19,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["def train_chatbot(directory, model_output_path, train_fraction=0.8):\n","  # read documents from the directory\n","  combined_text = read_documents_from_directory(directory)\n","  # removing excess new line characters\n","  combined_text = re.sub(r'\\n+', '\\n', combined_text).strip()\n","\n","  # split the text into training and validation sets\n","  split_index = int(train_fraction * len(combined_text))\n","  train_text = combined_text[:split_index]\n","  test_text = combined_text[split_index:]\n","\n","  # save training and validation data as text file\n","  with open(\"train.txt\", \"w\") as f:\n","    f.write(train_text)\n","  with open(\"test.txt\", \"w\") as f:\n","    f.write(test_text)\n","\n","  # save up the tokenizer and model\n","  # tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\") # also try gpt2, gpt2-large, gpt2-medium, gpt2-xl\n","  # model = GPT2LMHeadModel.from_pretrained(\"gpt2\") # also try gpt2, gpt2-large, gpt2-medium, gpt2-xl\n","  tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\") # also try gpt2, gpt2-large, gpt2-medium, gpt2-xl\n","  model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\") # also try gpt2, gpt2-large, gpt2-medium, gpt2-xl\n","\n","  # prepare the dataset\n","  train_dataset = TextDataset(tokenizer=tokenizer, file_path='train.txt', block_size=128)\n","  test_dataset = TextDataset(tokenizer=tokenizer, file_path='test.txt', block_size=128)\n","  data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","  # setup the training argument\n","  training_args = TrainingArguments(\n","      output_dir=model_output_path,\n","      overwrite_output_dir=True,\n","      per_device_train_batch_size=8,\n","      per_device_eval_batch_size=8,\n","      num_train_epochs=50,\n","      save_steps=10_000,\n","      save_total_limit=2,\n","      logging_dir='./logs',\n","  )\n","\n","  # train the model\n","  trainer = Trainer(\n","      model=model,\n","      args=training_args,\n","      data_collator=data_collator,\n","      train_dataset=train_dataset,\n","      eval_dataset=test_dataset,\n","  )\n","\n","  trainer.train()\n","  trainer.save_model(model_output_path)\n","\n","  # save the tokenizer\n","  tokenizer.save_pretrained(model_output_path)"]},{"cell_type":"markdown","metadata":{"id":"Sz115v-UmsgI"},"source":["## Use the implemented model and try to generate the text.\n","\n","### The \"generate_response\" function takes a trained model, tokenizer, and a prompt string as input and generates a response using the GPT-2 model."]},{"cell_type":"markdown","source":["### **<font color='red'>Output Length Limitation:</font>**\n","#### This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"],"metadata":{"id":"zgIFTDTsflqO"}},{"cell_type":"markdown","source":["## [generate](https://huggingface.co/docs/transformers/v4.41.0/en/main_classes/text_generation#transformers.GenerationMixin.generate)\n","\n","#### Generates sequences of token ids for models with a language modeling head.\n","\n","To learn more about decoding strategies refer to the [text generation strategies guide.](https://huggingface.co/docs/transformers/v4.41.0/en/generation_strategies)"],"metadata":{"id":"yOH0EQ6Cfddn"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"c9Om_EPhm0M6","executionInfo":{"status":"ok","timestamp":1716469773128,"user_tz":-480,"elapsed":20,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["def generate_response(model, tokenizer, prompt, max_length=250):\n","  inputs_ids = tokenizer.encode(prompt, return_tensors='pt')\n","\n","  # create the attention mask and pad token ids\n","  attention_mask = torch.ones_like(inputs_ids)\n","  pad_token_id = tokenizer.eos_token_id\n","\n","  output = model.generate(\n","      inputs_ids,\n","      max_length=max_length,        # Increase max_length to get longer outputs\n","      num_return_sequences=4,       # The number of independently computed returned sequences for each element in the batch.\n","      attention_mask=attention_mask,\n","      pad_token_id=pad_token_id,    # The id of the padding token\n","      temperature=1.0,              # The value used to modulate the next token probabilities.\n","      no_repeat_ngram_size=4,\n","      num_beams=4,\n","  )\n","\n","  return tokenizer.decode(output[0], skip_special_tokens=True)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eV84vvoETf6j","executionInfo":{"status":"ok","timestamp":1716469892808,"user_tz":-480,"elapsed":119700,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}},"outputId":"17fe41ed-1662-44cb-cbd5-f6d3425fba6a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## The main function\n","### The \"main\" function is the entry point for the program.\n","#### It specifies the path to the directory containing the training data and the path to the output directory for the trained model and tokenizer.\n","#### It then trains the chatbot using the \"train_chatbot\" function and generates a response to a specified prompt using the \"generate_response\" function.\n"],"metadata":{"id":"AHeMk4U1VZDO"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"5w-cAywDEKpZ","executionInfo":{"status":"ok","timestamp":1716469892808,"user_tz":-480,"elapsed":7,"user":{"displayName":"AMITKUMAR DUBEY","userId":"13607019546596109318"}}},"outputs":[],"source":["# the main function to store all files which will be use in the program\n","def main():\n","  directory = \"/content/drive/MyDrive/Colab Notebooks/Project/\"\n","  # /content/drive/MyDrive/Colab Notebooks/Project\n","  model_output_path = \"/content/drive/MyDrive/Colab Notebooks/Project/\"\n","\n","  # Check if the directory exists\n","  if not os.path.exists(directory):\n","    raise FileNotFoundError(f\"Directory '{directory}' not found.\")\n","\n","  # Check if the user has access to the directory\n","  if not os.access(directory, os.R_OK):\n","    raise PermissionError(f\"User does not have read access to '{directory}'.\")\n","\n","  # train the chatbot\n","  train_chatbot(directory, model_output_path)\n","\n","  # Load the fine-tuned model and tokenizer\n","  model = GPT2LMHeadModel.from_pretrained(model_output_path)\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_output_path)\n","\n","  # Test the chatbot\n","  prompt = \"What is Jacquard machines are made of?\"  # Replace with your desired prompt\n","  response = generate_response(model, tokenizer, prompt)\n","  print(\"Generated response:\", response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":368,"referenced_widgets":["7ab2afdee225448c84f0052bf64fa55d","e9a2065e47184803875daffe0f117842","1310c29fce8b430a9191d5c84e0546a8","1afed6c09c4a4ab89c1c9f28404223a6","826d99ac6be1476780099dfb001f4130","a73bde1f3055454fa9d23da1ea4f3249","c2f09bd29f3c434bb833599625867088","7ca15998709a4f7986455938bb5ca8dd","b23aa715a1244ff38e03df440510e98a","d8c194f6352d46128e2ad02e199e873b","a27eaa41ea55438c88622adc7eef1ae6","a73ef0a4ddde4db2b2f1f097879772d7","181f45c51c9b40e29fcdac6bc76d4a05","6e68964c3a3a447d9e1892cd1f200442","a79bcc69c37b408a81164fa802ddde54","4ebcec2ae84f4768ac01038aff1c7d55","a35aa7049d0e4d729019030b05f2277a","bb214e1c75f04a5ebacb7d286a0b57b9","237edfc4436243b39dad0d663c4d1cb9","3cd1db3ff35440b6a5f5948061a94a11","0f057b4dd1704994b70e3a6170f33ac2","7b35bd585d4e497fa1b967d425f49b62","6574e75fae4a499babc3cbbcb3e1c9b7","a88e019fa00447f8a30538b803962db0","8cae5a51e8be482abc392c862903672a","aa55a8dde4ec4c1baff7e6756aaa10fa","4901dcb304b0454fac0bb607f23bf310","8e1b9921b26646b3a5d8b01652bca3e9","4bce86c046fb409ead218cee26483e3b","4f7c9034f6344d099a7d4ec1922b0a6a","8cab61877970456f91f4d767312f2490","aede1b3782334fc98a0fc4e1806ade9b","d76fb01bc3e347d8b0418979f415251b","e37597055a684f3fad133bab5b5fe721","7266efea760e4809907aaf9e076e7a34","ae0a4540e49f42e6aca1d173f0a42ed0","a91bff77b15c47fc97623e89b66a6abd","69bb08356a8042859c8f5001ca266a2d","5ec9ad985dbe4e23b02bbbeebd27e674","4ba6f3d191cf4a2e9c64e8c491130608","97a046097a9a462986eeac9079ca4244","bb94d687bf704169aa3e370ca9f3321e","3bd78494476c42259685b852b7d89e3e","26b4917c3c5b41e69dc8501f24a07cc7","73a74431bc67417484e8ce203737598c","b223d6a53fe44fdaa2a6668b01ca5cad","eeeee8cba17245d196717ec599af5f97","7745c51416614a8796d13c0343e9c72b","43f6582592ea427bb532963caa30b1f8","4ec355848a714b5682f1e81d258e52f5","6ea96514044746f2a6699781b4071fb9","e43b752b3abe49f9a85d82ec4d36bdc1","80013759bbb14a9085e6bc3351e6e823","1b8124daefcc45e79722cf07db5ad043","5825f2632140419dadc11f81973daae8","61c477ae55394fd28b83421aae94022b","d9cf809b2bc24b29bd829b2a2ec72696","f01fcc2d847e4d1e8e1ae3d88a1b04fe","861749f051514a9db9a7772c31427ae1","de141691239447a690d4e887b205fafd","81edc4d719c34372b14e2546ffbf255b","e3c7d5416f99442aa64215c0588470ae","6d38ca8de22f442590b612e9373d9484","182824cf8ee24c10ae718fec5906af88","5a8062d02d61443f9d693ffe4e94dc4a","44dc43d85153487d9c87d18ef03dbaae"]},"id":"iiIVYQuZE_t1","outputId":"82c73b50-9b3e-4283-d01c-b573ef42be62"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ab2afdee225448c84f0052bf64fa55d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a73ef0a4ddde4db2b2f1f097879772d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6574e75fae4a499babc3cbbcb3e1c9b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e37597055a684f3fad133bab5b5fe721"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a74431bc67417484e8ce203737598c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c477ae55394fd28b83421aae94022b"}},"metadata":{}}],"source":["if __name__ == \"__main__\":\n","  main()"]},{"cell_type":"markdown","source":["# Now, let us test the model.\n","\n","Use the following code if you are only performing inference (generating text). This can be placed in a separate notebook."],"metadata":{"id":"tikgi0oiq8ys"}},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel"],"metadata":{"id":"6IdfgTByeDVB"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wuBmuGILW28NLyhta6Tohd_ACDqmYh6L","authorship_tag":"ABX9TyOZ//EtpffI7YuokXZxK7Ba"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"7ab2afdee225448c84f0052bf64fa55d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9a2065e47184803875daffe0f117842","IPY_MODEL_1310c29fce8b430a9191d5c84e0546a8","IPY_MODEL_1afed6c09c4a4ab89c1c9f28404223a6"],"layout":"IPY_MODEL_826d99ac6be1476780099dfb001f4130"}},"e9a2065e47184803875daffe0f117842":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a73bde1f3055454fa9d23da1ea4f3249","placeholder":"​","style":"IPY_MODEL_c2f09bd29f3c434bb833599625867088","value":"tokenizer_config.json: 100%"}},"1310c29fce8b430a9191d5c84e0546a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ca15998709a4f7986455938bb5ca8dd","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b23aa715a1244ff38e03df440510e98a","value":26}},"1afed6c09c4a4ab89c1c9f28404223a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8c194f6352d46128e2ad02e199e873b","placeholder":"​","style":"IPY_MODEL_a27eaa41ea55438c88622adc7eef1ae6","value":" 26.0/26.0 [00:00&lt;00:00, 1.41kB/s]"}},"826d99ac6be1476780099dfb001f4130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73bde1f3055454fa9d23da1ea4f3249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2f09bd29f3c434bb833599625867088":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ca15998709a4f7986455938bb5ca8dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b23aa715a1244ff38e03df440510e98a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d8c194f6352d46128e2ad02e199e873b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a27eaa41ea55438c88622adc7eef1ae6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a73ef0a4ddde4db2b2f1f097879772d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_181f45c51c9b40e29fcdac6bc76d4a05","IPY_MODEL_6e68964c3a3a447d9e1892cd1f200442","IPY_MODEL_a79bcc69c37b408a81164fa802ddde54"],"layout":"IPY_MODEL_4ebcec2ae84f4768ac01038aff1c7d55"}},"181f45c51c9b40e29fcdac6bc76d4a05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a35aa7049d0e4d729019030b05f2277a","placeholder":"​","style":"IPY_MODEL_bb214e1c75f04a5ebacb7d286a0b57b9","value":"vocab.json: 100%"}},"6e68964c3a3a447d9e1892cd1f200442":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_237edfc4436243b39dad0d663c4d1cb9","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cd1db3ff35440b6a5f5948061a94a11","value":1042301}},"a79bcc69c37b408a81164fa802ddde54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f057b4dd1704994b70e3a6170f33ac2","placeholder":"​","style":"IPY_MODEL_7b35bd585d4e497fa1b967d425f49b62","value":" 1.04M/1.04M [00:00&lt;00:00, 9.33MB/s]"}},"4ebcec2ae84f4768ac01038aff1c7d55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a35aa7049d0e4d729019030b05f2277a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb214e1c75f04a5ebacb7d286a0b57b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"237edfc4436243b39dad0d663c4d1cb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd1db3ff35440b6a5f5948061a94a11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f057b4dd1704994b70e3a6170f33ac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b35bd585d4e497fa1b967d425f49b62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6574e75fae4a499babc3cbbcb3e1c9b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a88e019fa00447f8a30538b803962db0","IPY_MODEL_8cae5a51e8be482abc392c862903672a","IPY_MODEL_aa55a8dde4ec4c1baff7e6756aaa10fa"],"layout":"IPY_MODEL_4901dcb304b0454fac0bb607f23bf310"}},"a88e019fa00447f8a30538b803962db0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e1b9921b26646b3a5d8b01652bca3e9","placeholder":"​","style":"IPY_MODEL_4bce86c046fb409ead218cee26483e3b","value":"merges.txt: 100%"}},"8cae5a51e8be482abc392c862903672a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f7c9034f6344d099a7d4ec1922b0a6a","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cab61877970456f91f4d767312f2490","value":456318}},"aa55a8dde4ec4c1baff7e6756aaa10fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aede1b3782334fc98a0fc4e1806ade9b","placeholder":"​","style":"IPY_MODEL_d76fb01bc3e347d8b0418979f415251b","value":" 456k/456k [00:00&lt;00:00, 16.3MB/s]"}},"4901dcb304b0454fac0bb607f23bf310":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e1b9921b26646b3a5d8b01652bca3e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bce86c046fb409ead218cee26483e3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f7c9034f6344d099a7d4ec1922b0a6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cab61877970456f91f4d767312f2490":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aede1b3782334fc98a0fc4e1806ade9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d76fb01bc3e347d8b0418979f415251b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e37597055a684f3fad133bab5b5fe721":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7266efea760e4809907aaf9e076e7a34","IPY_MODEL_ae0a4540e49f42e6aca1d173f0a42ed0","IPY_MODEL_a91bff77b15c47fc97623e89b66a6abd"],"layout":"IPY_MODEL_69bb08356a8042859c8f5001ca266a2d"}},"7266efea760e4809907aaf9e076e7a34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ec9ad985dbe4e23b02bbbeebd27e674","placeholder":"​","style":"IPY_MODEL_4ba6f3d191cf4a2e9c64e8c491130608","value":"tokenizer.json: 100%"}},"ae0a4540e49f42e6aca1d173f0a42ed0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a046097a9a462986eeac9079ca4244","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb94d687bf704169aa3e370ca9f3321e","value":1355256}},"a91bff77b15c47fc97623e89b66a6abd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bd78494476c42259685b852b7d89e3e","placeholder":"​","style":"IPY_MODEL_26b4917c3c5b41e69dc8501f24a07cc7","value":" 1.36M/1.36M [00:00&lt;00:00, 23.4MB/s]"}},"69bb08356a8042859c8f5001ca266a2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ec9ad985dbe4e23b02bbbeebd27e674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ba6f3d191cf4a2e9c64e8c491130608":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97a046097a9a462986eeac9079ca4244":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb94d687bf704169aa3e370ca9f3321e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3bd78494476c42259685b852b7d89e3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b4917c3c5b41e69dc8501f24a07cc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73a74431bc67417484e8ce203737598c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b223d6a53fe44fdaa2a6668b01ca5cad","IPY_MODEL_eeeee8cba17245d196717ec599af5f97","IPY_MODEL_7745c51416614a8796d13c0343e9c72b"],"layout":"IPY_MODEL_43f6582592ea427bb532963caa30b1f8"}},"b223d6a53fe44fdaa2a6668b01ca5cad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ec355848a714b5682f1e81d258e52f5","placeholder":"​","style":"IPY_MODEL_6ea96514044746f2a6699781b4071fb9","value":"config.json: 100%"}},"eeeee8cba17245d196717ec599af5f97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e43b752b3abe49f9a85d82ec4d36bdc1","max":666,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80013759bbb14a9085e6bc3351e6e823","value":666}},"7745c51416614a8796d13c0343e9c72b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b8124daefcc45e79722cf07db5ad043","placeholder":"​","style":"IPY_MODEL_5825f2632140419dadc11f81973daae8","value":" 666/666 [00:00&lt;00:00, 27.6kB/s]"}},"43f6582592ea427bb532963caa30b1f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ec355848a714b5682f1e81d258e52f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea96514044746f2a6699781b4071fb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e43b752b3abe49f9a85d82ec4d36bdc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80013759bbb14a9085e6bc3351e6e823":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b8124daefcc45e79722cf07db5ad043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5825f2632140419dadc11f81973daae8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61c477ae55394fd28b83421aae94022b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d9cf809b2bc24b29bd829b2a2ec72696","IPY_MODEL_f01fcc2d847e4d1e8e1ae3d88a1b04fe","IPY_MODEL_861749f051514a9db9a7772c31427ae1"],"layout":"IPY_MODEL_de141691239447a690d4e887b205fafd"}},"d9cf809b2bc24b29bd829b2a2ec72696":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81edc4d719c34372b14e2546ffbf255b","placeholder":"​","style":"IPY_MODEL_e3c7d5416f99442aa64215c0588470ae","value":"model.safetensors:  62%"}},"f01fcc2d847e4d1e8e1ae3d88a1b04fe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d38ca8de22f442590b612e9373d9484","max":3247159078,"min":0,"orientation":"horizontal","style":"IPY_MODEL_182824cf8ee24c10ae718fec5906af88","value":2023751680}},"861749f051514a9db9a7772c31427ae1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a8062d02d61443f9d693ffe4e94dc4a","placeholder":"​","style":"IPY_MODEL_44dc43d85153487d9c87d18ef03dbaae","value":" 2.02G/3.25G [00:24&lt;00:10, 113MB/s]"}},"de141691239447a690d4e887b205fafd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81edc4d719c34372b14e2546ffbf255b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3c7d5416f99442aa64215c0588470ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d38ca8de22f442590b612e9373d9484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"182824cf8ee24c10ae718fec5906af88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a8062d02d61443f9d693ffe4e94dc4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44dc43d85153487d9c87d18ef03dbaae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}