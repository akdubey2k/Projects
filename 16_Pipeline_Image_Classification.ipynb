{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hugging Face image classification\n",
        "-refers to the use of **pre-trained models** and tools provided by **Hugging Face** to assign a label or category to an image. It involves inputting an *image into a model that has been trained* to recognize patterns and features, with the output being the most likely ***class** the image belongs* to, such as \"cat\" or \"dog\".\n",
        "\n",
        "**Hugging Face** provides the infrastructure and resources, including a model hub, libraries like **transformers**, and tools like **AutoTrain**, to perform this task efficiently.\n",
        "\n",
        "### How it works:\n",
        "1. **Pre-trained Models:** Hugging Face hosts a vast collection of *pre-trained models* for various tasks, including image classification. These models are trained on large datasets and are ready to be used or fine-tuned for specific needs.\n",
        "2. **Pipelines:** The easiest way to use these models is through the **Hugging Face Transformers library pipelines**, which abstract away much of the complexity.\n",
        "3. **Input:** You provide an image (*as an image file or local bytes*) to the pipeline.\n",
        "4. **Classification:** The model analyzes the image's pixel values and predicts the most probable class.\n",
        "5. **Output:** The result is typically a set of classes and associated confidence scores, indicating the likelihood of each prediction.\n"
      ],
      "metadata": {
        "id": "cVICzIJHov-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key aspects of Hugging Face's approach:\n",
        "- **Model Hub:** A central platform to find, share, and use pre-trained models, including vision transformers.\n",
        "- **AutoTrain:** A service that simplifies the process of training custom image classification models by uploading labeled example images.\n",
        "- **Libraries:** Transformers and Datasets libraries provide the core functionalities for data loading, model inference, and training.\n",
        "\n",
        "### Applications:\n",
        "- **Keyword classification:** Assigning a keyword to an image.\n",
        "- **Image search:** Organizing photo libraries.\n",
        "- **Medical image screening:** Helping to detect signs of disease.\n",
        "- **Crop health monitoring:** Assessing the health of crops."
      ],
      "metadata": {
        "id": "cwH8QEV4o3i4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ah290abPoisT"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_classifier= pipeline(task=\"image-classification\", model=\"google/vit-base-patch16-224\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "6d9c4bc21f6b4f4da1a6815f1e1c1879",
            "77b15a46ba24443c90b92d6955455da6",
            "d4e63adb1aae495f82a8a3b86bea3618",
            "5d0230c9e9824d70a0efba3d83c81398",
            "3b3437e9344d47518362a1ce883c763e",
            "0120685722074a2db786865f40a536f6",
            "4cf985c461f34b93bd58deac35c355b8",
            "7144182c30344a368bb7e573cb7c93f1",
            "7a95606de5f643acbc923d0f52ce6a08",
            "01f2ea50a4b9475aa7b14ac857df88d5",
            "f5d469f438f54e34bda044718a27c260",
            "e99fba70fcee47c4b9afa8074d07a1fd",
            "8e2707d0a160438ea089ad20ba60c171",
            "acec54d362724821b14f2cce4cca37fd",
            "bd835bab29fb4dcda4747550ad51aecb",
            "1c94274b149f4878b800c63600c9f41a",
            "052294d09b94440baf3c93113ad40d1f",
            "71b73e2052ed47dda97d649d92176494",
            "3664765aa62a4ef2b9fdd08007bfa7e8",
            "1968fd6a70654dbd9c970ee29bab1b18",
            "b00678691e9342e7a7024951c383c4bf",
            "e4fcc50a58cd43d1b744900a200dc347"
          ]
        },
        "id": "4u8p8Gg6p5gr",
        "outputId": "656a8ea5-53d7-4acd-ebcc-49475bef4895"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d9c4bc21f6b4f4da1a6815f1e1c1879"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e99fba70fcee47c4b9afa8074d07a1fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = \"world_search_bg.png\"\n",
        "image_path = \"Amit_Visa_2022.jpeg\"\n",
        "\n",
        "results = image_classifier(image_path)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_uZ38cRrWGS",
        "outputId": "c12e2620-8dc5-4b5b-f85b-8c0cd55b6347"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'envelope', 'score': 0.7954962253570557},\n",
              " {'label': 'rubber eraser, rubber, pencil eraser',\n",
              "  'score': 0.04921957105398178},\n",
              " {'label': 'rule, ruler', 'score': 0.029204238206148148},\n",
              " {'label': 'binder, ring-binder', 'score': 0.014957639388740063},\n",
              " {'label': 'packet', 'score': 0.011321413330733776}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}
