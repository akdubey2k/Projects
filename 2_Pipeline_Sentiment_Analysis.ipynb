{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# `pipeline()`\n",
        "The **pipeline()** function supports multiple modalities, allowing to work with **text, images, audio,** and **even multimodal tasks**.\n",
        "\n",
        "Here, we focus only on text tasks, but it’s useful to understand the transformer architecture’s potential, so we’ll briefly outline it."
      ],
      "metadata": {
        "id": "N9_jXp8DHj0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Ew7Iu_glEocA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314,
          "referenced_widgets": [
            "15035ee8809040f48069758a62fa4320",
            "0e0414fa52434f87be15b58e1adeca8f",
            "64e70305ce914fbe87ab58ebd751d1a0",
            "873586eb0cea4855aeadd6e7fe1435d2",
            "6e81e4f6e64346ab8989eb729e2f8785",
            "679bca7ac3c9462db16d2eda9149cb33",
            "6cf6df2a5cd240cb9a5cb7b8f3904f4c",
            "afd438f954514630ae254a081d2f817f",
            "49c3c1b330634f16b4958327bebcb231",
            "1d4e57f2f2a6405d94eb704f50aa2be1",
            "946bc56d7be64bca9338f6819571ea6f",
            "bf4b77a520884e24ab1c88aa741bb324",
            "a9c9de670a5e4bc4a668c04a8fe7283e",
            "a0f7820173b441f583d3ca69087ee1ef",
            "f49d2f6956fd43aeb263f0a04dfddddf",
            "1d7ec135c9b149dd801d61b82fbbc283",
            "f0b4aa47343a411cb7764b663204e831",
            "39e469efbfd244e590cf231db17de348",
            "7f351ff754bf441da474ebedce0a9444",
            "e417cc10da2648a6ba7ca78b64bad4ec",
            "803c226a08354a10bdc60fdc28a524de",
            "2685e4b0bffa4d83b5b7b9e43ac98d4e",
            "b3be55b1056c4dea86106d12b088986d",
            "6d8f8bb7482b45ad9cf0bf4170e14ecd",
            "2bde1249f294471097db5edd71b14bf6",
            "0656a545bc8646b191ebcda86a3c29ec",
            "ff70896fce684c2697c1706a14e9ac2d",
            "aec3a5b47ff9404f89030287ed0eeb9e",
            "18be93b742d84b759a9cc5628eeca6b4",
            "5b6b1be48b324239b3496b75dd49e997",
            "4127ddc623ed4c5a818dac48b198dff6",
            "3a9f511b34ce436690e995fba5cd3308",
            "5f5e28663ecf4c18b4270f392242e4b8",
            "54bad528a1904890b40a99e57356f238",
            "5444ab68c6ff4b469eeff83b00b49a07",
            "d87e20cdf6bf4b4ea08ed857a7d5eab7",
            "9bd7b75899b547c68813f4e798675231",
            "eeffed0ac3ca4fc096526e75352050de",
            "bbfc37200ccb43319a5cc2146cc11e55",
            "12b3e165c2724878bd432e4e8677349b",
            "acc052481c3f45e9846a0b26546c9bec",
            "26dadfd852a24da9815ec698f46e16d1",
            "c4e9cc55517647879feae1c31039e36e",
            "02139f00ff6e4ec5875190a2beb7a02e"
          ]
        },
        "id": "jC0y43lNDJfF",
        "outputId": "af876225-eec7-42e4-db58-64684df6bc53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15035ee8809040f48069758a62fa4320"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf4b77a520884e24ab1c88aa741bb324"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3be55b1056c4dea86106d12b088986d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54bad528a1904890b40a99e57356f238"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, this **\"pipeline\"** selects a particular *pretrained model* that has been fine-tuned for **sentiment analysis in English**.\n",
        "\n",
        "The model is **downloaded** and **cached** when we create the **classifier** object. If you rerun the command, the **cached** model will be used instead and there is no need to download the model again.\n",
        "\n",
        "### There are three main steps involved when you pass some text to a pipeline:\n",
        "1. The text is **preprocessed** into a format the model can understand.\n",
        "2. The **preprocessed** inputs are passed to the **model**.\n",
        "3. The **predictions** of the **model** are **post-processed**, so you can make sense of them."
      ],
      "metadata": {
        "id": "FwW_Spy8I7za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier([\"I'm very focused and intelligent leader\", \"I have built an organization which is world's best in technology\", \"My organization is worth of more than 200000000000 Billion $\", \"I hate lazy people, who always do the procastination\", 'I like the person who is silent but highly aggressive in work'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7JVbsJPDgrV",
        "outputId": "1537ae95-4806-47a5-d564-967a03c4d099"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.999874472618103},\n",
              " {'label': 'POSITIVE', 'score': 0.9998679161071777},\n",
              " {'label': 'POSITIVE', 'score': 0.9956153631210327},\n",
              " {'label': 'NEGATIVE', 'score': 0.9935566782951355},\n",
              " {'label': 'POSITIVE', 'score': 0.9760797619819641}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#distilbert/distilbert-base-uncased-finetuned-sst-2-english\n",
        "is a specific version of the **DistilBERT** model that has been fine-tuned for **sentiment analysis using the SST-2 dataset**, while the **revision 714eb0f** refers to a specific commit (or state) of the model's files on a platform like **Hugging Face.**\n",
        "\n",
        "The model is designed to classify text as **positive or negative,** with the **\"uncased\"** part indicating it processes text without regard to **capitalization, and \"distil\"** referring to its **smaller, distilled version** of the **larger \"BERT\" model.**\n",
        "\n",
        "### Here's a breakdown of the components:\n",
        "#### distilbert\n",
        ": The name of the base language model, a distilled version of BERT, known for being smaller and faster while retaining much of BERT's performance.\n",
        "\n",
        "#### base\n",
        ": Indicates the size of the model.\n",
        "#### uncased\n",
        ": Means that all text is converted to lowercase before processing, so \"Hello\" and \"hello\" are treated as the same word.\n",
        "#### finetuned\n",
        ": Signifies that the model was pre-trained on a large corpus of text and then further trained (fine-tuned) on a specific dataset.\n",
        "#### sst-2-english\n",
        ": The fine-tuning task and dataset. This is the Stanford Sentiment Treebank v2 dataset, used for binary sentiment classification (positive or negative sentiment) in English text.\n",
        "#### revision 714eb0f\n",
        ": This is a specific identifier for a particular version or commit of the model's files hosted on a platform like Hugging Face. It allows users to refer to an exact state of the model, which is useful for reproducible research and deployment."
      ],
      "metadata": {
        "id": "zvRNtZhvPmkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text pipelines\n",
        "\n",
        "* **text-generation:** Generate text from a prompt\n",
        "* **text-classification:** Classify text into predefined categories\n",
        "* **summarization:** Create a shorter version of a text while preserving key information\n",
        "* **translation:** Translate text from one language to another\n",
        "* **zero-shot-classification:** Classify text without prior training on specific labels\n",
        "* **feature-extraction:** Extract vector representations of text"
      ],
      "metadata": {
        "id": "KMufopopQ1DZ"
      }
    }
  ]
}
