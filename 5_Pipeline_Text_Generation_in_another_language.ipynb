{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EICHH_UTHvoB"
      },
      "source": [
        "# QuantFactory/BharatGPT-3B-Indic-GGUF\n",
        "* This is **quantized** version of [CoRover/BharatGPT-3B-Indic](https://huggingface.co/CoRover/BharatGPT-3B-Indic) created using **llama.cpp**\n",
        "\n",
        "* The model is designed to *generate multilingual outputs across multiple Indic languages.*\n",
        "\n",
        "* The model has been trained on a 12 differnt diverse language and curated dataset comprising **Hindi, Punjabi, Marathi, Malayalam, Oriya, Kannada, Gujarati, Bengali, Urdu, Tamil, and Telugu.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load text generation pipeline with a multilingual model\n",
        "# (You can try 'facebook/mbart-large-50-many-to-many-mmt' or 'gpt2' variants fine-tuned on Hindi)\n",
        "generator = pipeline(\"text-generation\", model=\"facebook/mbart-large-50-many-to-many-mmt\")\n",
        "\n",
        "# Hindi prompt\n",
        "hindi_prompt = \"भारत एक महान देश है और\"\n",
        "hindi_output = generator(hindi_prompt, max_length=50, num_return_sequences=1)\n",
        "print(\"Hindi Output:\\n\", hindi_output[0]['generated_text'])\n",
        "\n",
        "# Spanish prompt\n",
        "spanish_prompt = \"La inteligencia artificial es\"\n",
        "spanish_output = generator(spanish_prompt, max_length=50, num_return_sequences=1)\n",
        "print(\"\\nSpanish Output:\\n\", spanish_output[0]['generated_text'])\n",
        "\n",
        "# French prompt\n",
        "french_prompt = \"L'avenir de la technologie est\"\n",
        "french_output = generator(french_prompt, max_length=50, num_return_sequences=1)\n",
        "print(\"\\nFrench Output:\\n\", french_output[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427,
          "referenced_widgets": [
            "6ef41910161f4e489ac122d79a946eff",
            "70fe1e325e2b409ba4a5fe45ede16619",
            "f62ae571db3d43ddbe21e8d00e786fb8",
            "9467db8bb2364097beeb002a261cd5de",
            "c5ebcec1050e482e8cb60eb6db40d2fb",
            "05791c0794ad4dc2b4ad27e9d13dc07e",
            "8c03e752f0204d7ca82385223ebc05b0",
            "a493e0bad9664a619f31f9e0a7cdcd84",
            "5dff641fc73a4d159b94bba7ec2f05b1",
            "e3792cc24c944cb8b690a1f2f83ee9e0",
            "dbed677e3423498a9b678bc2cdff5afe",
            "2ed5038bfd914382a12d89db6d301946",
            "c9fe2a9bbc814d3faf3fa5398cd1f840",
            "5d889dea8a9d4f338c418a8238674167",
            "864a3028c6c14459a5332c26790e4856",
            "f7c11e0d513d43e0ae20046c887d75ea",
            "299770888a7d4f6db50e5553c528a6c9",
            "a78f0b2502764bc3aee22505dabc1757",
            "841634de05004752a413de8dbed02b3b",
            "f3f3bba27c9f484fbb6c8ed2c4dff32c",
            "54b3468ff32747b38f163e5a96bceb8e",
            "f969de134acf45a787bbdca6bda050d2",
            "ee55801eae4b4d01acdcfeb2528bcbcd",
            "2396335bac3f4651a38bedbf6127450a",
            "88b69f005ca5445aaffb338dd50d6e4d",
            "5bdb0021106749a4a6302cc9ab9b50df",
            "acfc74cc60d248a89c2f81cca48e17f8",
            "694e9932820047c9be109371e3c48992",
            "bc4f90e661bb4a9cb8a858dd3cee4b7f",
            "4f6b79ba1b704d908f72d89874b23ec3",
            "1db57336c6274843a1115528fb19652d",
            "5d5cca95d68440fcae438c899109edf9",
            "8a84fac4d244453ca4a33665036c5b7a",
            "28422d432c114ea99be9fc8ca60b950e",
            "eea14220e08c49639d29f8bc0aad026f",
            "b68384471a7c42e2a85142f4e3b692bb",
            "e4b18158ccd8434ca84fce26d7fa39ed",
            "dedbf113e5f74d54ae4af68f4daacc7a",
            "229d2cb8357c459890f25b0a6c8c5188",
            "02c322681b984084abccdbca38d6baef",
            "1eb03c1ce7984e8dbb87162542b686f9",
            "89561625b642462b866e5d792731973b",
            "5d9c3f93908444348e6c676861c56bb6",
            "8616eb3737be47c9aa60a2bf2568525b",
            "2c95023a6e064aab8ec02e60a2ea8318",
            "625854ef413d4457bfe269e0d346a5ec",
            "c8b5b93747a946a88015fb7aae8309c9",
            "d9b00c9606ec411884610ca600160dae",
            "1fe8bb49af864be8b2215df5be52a7a2",
            "b322a340912b446ba1e94a01b3f1628a",
            "61a2ab2f839e44f4ad39c621a1055790",
            "9a05bafded9049119bc966b1c686b01a",
            "0a8fc3db814244efae72219f8b88237c",
            "6b9bfd952b804c509062b7776a534431",
            "595d9cede44e40988f5da4249ced22d9",
            "9fd8e335309e4ec3b7e96dbdadd07bfd",
            "b8f8aa61973e47658682218763411062",
            "44aac1bd8d324ad5845772c2a11eeca8",
            "8bde233411bc40eca477e8fb71003d49",
            "3dfe011d02de41c28e4ef7ea57b348a0",
            "a0ad269e22b447bb9a810a1405390e3c",
            "539cffc57e8445bcb9562742ad2012c6",
            "12e190d044ef4c3bbf2b3b9468f1f037",
            "a1459cce6a5545ca9464525c3fb6005f",
            "eac22bee374740bb9f5b43299f335f69",
            "6bd10347eb3241b69e5c4760f48bcac0"
          ]
        },
        "id": "5HGPOuOExtAH",
        "outputId": "25d45aba-c8b9-4dc9-9ee8-e7dd0388adad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ef41910161f4e489ac122d79a946eff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ed5038bfd914382a12d89db6d301946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of MBartForCausalLM were not initialized from the model checkpoint at facebook/mbart-large-50-many-to-many-mmt and are newly initialized: ['lm_head.weight', 'model.decoder.embed_tokens.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee55801eae4b4d01acdcfeb2528bcbcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28422d432c114ea99be9fc8ca60b950e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c95023a6e064aab8ec02e60a2ea8318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fd8e335309e4ec3b7e96dbdadd07bfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hindi Output:\n",
            " भारत एक महान देश है और وت وت وت وت وت وت وت وت وت وت وت وت وت voľne voľne voľne voľne voľne voľne voľne voľne voľne voľne voľne voľne медији медији медији медији медији медији медији медији медијиॠॠॠॠwhichwhichwhich\n",
            "\n",
            "Spanish Output:\n",
            " La inteligencia artificial es investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu investeeringu\n",
            "\n",
            "French Output:\n",
            " L'avenir de la technologie est Бизнес Бизнес Бизнес Бизнес Бизнес Бизнес Бизнесなのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのになのに\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB6BLEWkDtSC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9N9JRfUMy45"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b5ijpAFNODV"
      },
      "outputs": [],
      "source": [
        "# Load HF_TOKEN securely set as a secret in Colab\n",
        "HF_TOKEN = userdata.get('dev-token')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603,
          "referenced_widgets": [
            "71a4e0a2a4df4ba2bc84faad8e264fc6",
            "504d6ffa072945f9847867dcc9de4863",
            "dba31fc2620e49cda7c31325ce0b438b",
            "53bd2a5259934eaaa406a73720381b8c",
            "4a78a7c41f8640228631c417b460ee50",
            "9cd4cddf164743fb9415f1654851789a",
            "5bd076e121224157bb31f21625303050",
            "1387301a782643eeb3bf7a094fb3a935",
            "b08dc2c2b8744b7b83545255c139b8d6",
            "1d6e5e3e4a374dcbaf65319ea00fc1d2",
            "bb2e7483bac44784bac4db3f90388573",
            "d0c956cea91a4d399dbaeeec6d805c8b",
            "2ad92ee4d42b42f780594f59f747b857",
            "a338e10ffdcc4963824364a6c5a3d9a6",
            "69b7774a429f4b93a222da273de1986a",
            "3385e9cc410b41349457eebd0657ad5c",
            "a00db2b1cf52402e9c0a2be62f1eece5",
            "9a05d15b1bc44bd79a701abda424edcb",
            "0d545d63ef6d4d85914c9554a4bf1029",
            "0798b14faa4b4f4cb000c902ed36f8c7",
            "11312c746b4f4478993133e7356bd6a8",
            "8b92a9b72f584176bc9e79a849273edd",
            "fba9010698ee41c18df84a56f17ec9a2",
            "7dad1e42d8a14edc9a673c0dbe74171e",
            "57c6fa62a01842f1879057faaf555b78",
            "9b2905f31d414ea18dcc0892afeaad42",
            "fedee53202a04d4d919fdc6826066ad1",
            "03efbeb8b2d94e518bcf1e0ce19ae48a",
            "b291d7f1560f452181177a40b7348500",
            "6c687537ac9c44bdae928bfcb8e248e3",
            "7ef0d1b61bcd4197a6cc1bf139c77939",
            "9931e381a44645e796e53415035d07dd",
            "bffa533e8f0f4275bc7c19088a138746",
            "fe21ff6eab9c4d978206efef9c631018",
            "22fbae225b0947d5b9a499621d4fdb74",
            "3ca766fab4de4d89a605b64392623bc1",
            "42c9484a5a564758aa5d20a62357dc77",
            "543ceee1a7af486c9621af0462fa9946",
            "5c9a01d6c3794b0bb35101c6a81d664d",
            "0416106f9acd42f6b8e309011e25c196",
            "0c58de1dc72f48efaeefca41c97a5fbb",
            "ba7df6db0c634ee69b92febfeb97d5d1",
            "dc1159ab4c83425fa2c6b630bc3b93db",
            "cfcb8386e2da402bb6dc4ca5a1495c97",
            "b3a6c2c72ee6487e911aa9f9ad39c742",
            "d1d6c3163f104e169e17f016bde85613",
            "d1410809b3544b45a5c3304a0176af07",
            "e66d6eb4f1744c04bc0fea9b5654d054",
            "e900131a660a48b0ad5113eaf0a6cf0d",
            "88b23ba2d3ae460dbd0d9b661af6ebb1",
            "331d01867f614b81b557220924c029cb",
            "e16848f3acac4ba0b834973b81405915",
            "2e4d8233e30b4937847f4049408b17a9",
            "4dc41d10a71d499ca8f60ab1d24846f3",
            "369d5003f2e8468f8cc65b713a9236c2",
            "255d0308ff114f6e8252b5f7248915cb",
            "87b523526226491fb5cdf970fb2265c8",
            "b885c575dcf84f96b082c61baa03fea8",
            "71dbbc7feec84cb78b6ce85ef4918802",
            "0ac5f7c2378448ea871988142a71e9d2",
            "7d2122ab90a848c7b3a88b3942378763",
            "39b20f11c01e48babcc11d414f0001ac",
            "0156e684695b476494a314a1bcd0d9ec",
            "c236f42d53d643c3a2672735765f841c",
            "a8a82737eb0645b4bbfa061123e05d64",
            "8c2b813c20864127b6ea1a1db16f7fe6",
            "150a8d7094f04fde8c30002872b3446c",
            "8746b108adfa46d4b5263d114ce6422c",
            "9654ef547a064501a18ecea9ed60cf43",
            "d7a6ecaa01c84dff884730aeeec48e5a",
            "4041f468353b40189835b5bcd428bdbb",
            "175e2ebe476f445d85cc65cb9d6d1413",
            "29840e9e3461431ba6311c63c94f223f",
            "3025588246ee456eb86f461ade2ff212",
            "607dd106f276450e95437773725ed41b",
            "c5ccb97bfc284d62927445520d616f11",
            "42ea4eeb06e548769c79b435f0073ead",
            "411774c35c4548c19d7b9220fbc4f3bf",
            "abee6a77ea324ef5af3b741ed55008ab",
            "a15a1aa7e2664836b51016ca2fdbe896",
            "c03c1a3b55d0457aad723aea138ab19c",
            "615b05cfbba1462594b44782196f22ea",
            "fc63fd8bb3954dcfae7ff26992349efb",
            "32fea2194be1428f83f5e3fe64d64c9d",
            "e24f2aa5650e4060b3ab3c148c7df8bc",
            "2fb50908fe9e424d84277892b756cf9f",
            "12b3e746e6d342388b3c9b3634b0fc77",
            "06d3f39a490b43c19782c81caf57b4d6",
            "4f457e3f999d4efda03598d246af38cb",
            "5b6df3af8d7942e68996a64aa33d83e3",
            "61f5a09a95c5467ea6dc41bd803ac36f",
            "cef7eef426814c9f9e811f1cb21fe425",
            "ade4cf7042ce4d4986ba171bc668c6c5",
            "3e3a00d81db04bba8ed0eea903e59592",
            "7f1b25eae9e44d1c91b1865aede2fd3a",
            "f51c36c9951a4c4193de8f58e57bac2e",
            "94c18e755622441bbb275287df26beb4",
            "8022a61d46ca4eb495d15f3b4b3df03c",
            "a80114b37866443380585e24355838a2",
            "dde71d95c1734be1b761926b2d30027c",
            "49b0666185324dcdaab262f9c529f63c",
            "426dc6821a724b74a7204edcd0c6c57e",
            "45b72ed661e4413f8c8e26b379cb5c4e",
            "24326216a5fb4d3db46d9f8bc526135d",
            "5f358c50cb1244638f43b043b70a4a8e",
            "d9571e638931439eb4821dd89599d12d",
            "118c2b6c2c9e45dfae02c906b3386996",
            "8146769edabd44feacc5025f98ff29fd",
            "cc66ff9ae4034e0c8e1298f6676c3689",
            "9a97c58955c44fb5838f0b4560d9c96b",
            "a705349445eb4c08ade198c410ec27a7",
            "54eaa4db7e7d4029bb6b033307057e4c",
            "0f86054c8b1f4798800f777bab1961df",
            "d4be6ac8bb0e4be8a83c0311fee6268d",
            "b2445cbdffed41dd89c83c56ef2acd53",
            "c16e98f3be514077992e277b38a8f508",
            "7e43ab9bec954b4db74dc2ee285f1546",
            "be3e638adb0d4d16bc1fd85ba4b2b8e6",
            "fe9a26b256f9428a9255a989c235e539",
            "55626e46b7b145deb4ec25e15a19296e",
            "506edfa7636c42e383a5786e5a0ed668",
            "4da14bd0563642ca94bfe2d5693082f9",
            "8092a116590a4c5d8c7a1231b6a08d04",
            "44227f1ca8fd4cfea1e30f122d7524c0",
            "541e0f9be6844c4c8e4466a3c0bd7425",
            "ac52bf3edab445be8265039add8274c5",
            "497481e185b6423d889e70898b1c170f",
            "9f6dcf94af0b44b9a9a3bbc80332e00f",
            "284072e11aec4c6b84c168477fe7724c",
            "0586e1dfd1a5406585bc37fea8f8a762",
            "06d2b068d6c0471882a8878f0c07f069",
            "15380f2e8b28492cb7089aa17da9ee92"
          ]
        },
        "id": "yFL1mX1vNhQg",
        "outputId": "8e8219f1-3c31-4abf-9f0a-99855c2083a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN secret found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/911 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71a4e0a2a4df4ba2bc84faad8e264fc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c956cea91a4d399dbaeeec6d805c8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fba9010698ee41c18df84a56f17ec9a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe21ff6eab9c4d978206efef9c631018"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3a6c2c72ee6487e911aa9f9ad39c742"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/503M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "255d0308ff114f6e8252b5f7248915cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/1.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "150a8d7094f04fde8c30002872b3446c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "411774c35c4548c19d7b9220fbc4f3bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f457e3f999d4efda03598d246af38cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dde71d95c1734be1b761926b2d30027c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a705349445eb4c08ade198c410ec27a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/439 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4da14bd0563642ca94bfe2d5693082f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Hindi Text: Translate the following text from English to Hindi: Amit, is a high impact AI reasearcher, sharp in focus, relentless in drive and always step ahead. He is known for his work in developing innovative solutions to complex problems using AI and machine learning. He has also worked on various projects including ones on data science, business intelligence and analytics. रचनात्मक संवादात्मक अनुभव प्रदान करने के लिए AI को सशक्त बनाने के लिए, हमारे डेटा सेंटर को तैयार करने के लिए हमारे टीम को 10 दिनों में काम कर रहा है। हमारे डेटा सेंटर की तैयारी पूरी होने पर, हम AI को शक्तिशाली बनाने के लिए एक नया सॉफ्टवेयर विकास कार्यक्रम शुरू करेंगे। इस कार्यक्रम में, हम AI को संवादात्मक और सुरक्षित बनाने के लिए नए मॉडल विकसित करेंगे। हमारे डेटा सेंटर में AI को शक्तिशाली बनाने के लिए एक नया सॉफ्टवेयर विकास कार्यक्रम श\n"
          ]
        }
      ],
      "source": [
        "if HF_TOKEN is None:\n",
        "  print(\"HF_TOKEN secret not found. Please set it in Colab secrets first.\")\n",
        "else:\n",
        "  print(\"HF_TOKEN secret found.\")\n",
        "  login(HF_TOKEN)\n",
        "  # Initialize the Hindi text generation pipeline\n",
        "  model_id = \"CoRover/BharatGPT-3B-Indic\"\n",
        "\n",
        "  hi_lan_gen = pipeline(\"text-generation\", model=model_id, token=HF_TOKEN)\n",
        "\n",
        "  # English input sentence\n",
        "  eng_sent = \"Amit, is a high impact AI reasearcher, sharp in focus, relentless in drive and always step ahead.\"\n",
        "  # hindi_language_generator\n",
        "\n",
        "  # create prompt for translation\n",
        "  prompt = f\"Translate the following text from English to Hindi: {eng_sent}\"\n",
        "\n",
        "  # Generate the Hindi translation\n",
        "  output = hi_lan_gen(\n",
        "    prompt,\n",
        "    max_length=100,  # Increased to accommodate translation\n",
        "    num_return_sequences=1,\n",
        "    do_sample=True,  # Enable sampling for more natural output\n",
        "    temperature=0.7,  # Control randomness\n",
        "    top_p=0.9,       # Use nucleus sampling\n",
        "    pad_token_id=hi_lan_gen.tokenizer.eos_token_id  # Handle padding\n",
        "  )\n",
        "\n",
        "  # Extract and print the generated Hindi text\n",
        "  translated_text = output[0]['generated_text']\n",
        "  print(\"Translated Hindi Text:\", translated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfcJL3i_KWIL",
        "outputId": "aa8b1786-7b58-4c7e-d197-dc9bd1692b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Amit, is a high impact AI reasearcher, sharp in focus, relentless in drive and always step ahead. He is a master in AI and ML with expertise in NLP, ML and AI in product development. He is a pioneer in AI and has worked with many top companies including Google, Microsoft and Amazon. He is a popular speaker at many conferences and a sought-after expert in AI and ML.\\nAmit has a wide range of skills including:\\n* Machine Learning\\n* Artificial Intelligence\\n* Data Science\\n* Data Engineering\\n* Data Analytics\\n* Product Development\\n* Business Strategy\\n* Innovation Management\\n* Entrepreneurship\\n* Leadership\\n* Product Launch\\n* Agile\\n* Cloud\\n* DevOps\\n* Cybersecurity\\n\\nAmit's Recent Work:\\n* Building and leading AI research teams at top companies\\n* Developing and implementing AI-based solutions for business growth\\n* Providing AI-based solutions to top companies\\n* Developing and teaching AI courses\\n* Writing articles on AI and ML\\n\\nAmit's Expertise:\\n* Artificial Intelligence\\n* Machine Learning\\n* NLP\\n* AI in Product Development\\n* AI in Business\\n* AI in Healthcare\\n* AI in Finance\\n* AI in Government\\n* Cybersecurity\\n* Cloud Computing\\n* Data Analytics\\n* Data Engineering\\n* Data Science\\n* DevOps\\n* Agile\\n* Entrepreneurship\\n* Leadership\\n\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "hi_lan_gen(\"Amit, is a high impact AI reasearcher, sharp in focus, relentless in drive and always step ahead.\",\n",
        "  max_length=30,\n",
        "  num_return_sequences=1,)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the translation pipeline\n",
        "translator = pipeline(\"translation\", model=\"facebook/m2m100_418M\", src_lang=\"en\", tgt_lang=\"hi\")\n",
        "\n",
        "# English input sentence\n",
        "english_sentence = \"Amit, is a high impact AI researcher, sharp in focus, relentless in drive and always step ahead.\"\n",
        "\n",
        "# Perform translation\n",
        "translated = translator(english_sentence, max_length=500)\n",
        "\n",
        "# Print the translated text\n",
        "print(\"Translated Hindi Text:\", translated[0]['translation_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326,
          "referenced_widgets": [
            "45974752d2d84dff83b179b1d732caac",
            "5ea2bf53724940abb6b64d0dae070d90",
            "cf8db9a45d324f99b30085e0637cb503",
            "658e0b50dcae45d589f6fc4898e46f90",
            "8fed82a00a08477fbb8befa1553d5190",
            "af83a5a4624e4f0faa46670055e8196d",
            "25ce1750fdf44ed6b3ad067c18dd9029",
            "c2ed14581bc947d38cca5f710cc2b378",
            "5f4d1e2555d749dfbacac50356fd2635",
            "847710f6c99147b48732c6a9a46b2c83",
            "0f19cd87479a4d5d96282387d86143d6",
            "e0f58cdcacf144298a1df8debc13f717",
            "995e0cd689ab409ebbc5c9fe19e7fc95",
            "5c209337a54a4a7a84fab25ca4a4ebb8",
            "a3e173ea94c74fcb9ed2efc1978a9cc6",
            "702d6c8ce8d2453d89cbfad9f58db543",
            "a90a9af201bc4da0abe268ddf50e4a02",
            "e043dd49c3bb4d3893e96f27886885d0",
            "34fc62aae5154b738b8c61b964af057f",
            "3a30904a41fb497686fa8f61d4e0ca7d",
            "e401203ac0164ccc85cdd248e217ec5e",
            "0ae17a0ea16948c2aa61ffab6a486bff",
            "320b3d72d5704117941087f25edd025a",
            "30f8cb7c055848879decb38ba4b55ac4",
            "9090808c2d9f49b5ac531f179aaa1b24",
            "c26c794cdb8d48348c43d3e0a2891110",
            "c74601dfca35467d8b80ca6a002ac7f1",
            "5feca3cb49674c288644650c713dabc3",
            "df54fbc5710b4ed4851f82694ed9ad52",
            "835fca5840f340978e889a373123fa04",
            "c71dd20ac5ab4ec79c9a2cdff5588688",
            "86968a812a1741c48a5156320e2346bf",
            "91513bf5618741058c5a99109c26327a",
            "8ef4f36e1c2041809672eb5eef8f9848",
            "d7c13be2c44046c9951b37198d919588",
            "9135d4832fe74ba688afffd6f58a8c4c",
            "01c5f64bad11410f838846e8f5287e62",
            "283af89b6f194f7fa5686227775c38a4",
            "ff66e8834bfc4d629f20c9fe830454d0",
            "1de887e5b4ab484b8ae871b171d028d1",
            "0999b401be3e45489992f5f0e54fbc9e",
            "d9feb3b88ef54779a8b082b9cca2f8d8",
            "c14ba1523ae04959a07389e44c06944a",
            "d3a735cb7fd04a1b9efee63d26f603af",
            "10f5b9fae11b4f7c8dba7ed79df7b6c4",
            "7ad4d86ed03d4eb88ae4155195f9c2ac",
            "7c657d5f9ea34c2f810c9ae559f98d0f",
            "07ac64c0ee4c4631a167dfb3c7e03f06",
            "deb9f3e24cae430b89aec91fe81b2954",
            "b482d35defe54866bbbec4921effffd8",
            "3bd375c2a3db4cb78b720bb056b59ca9",
            "dbe59062942f49f78531e679a4f952fd",
            "8d1bd10eb97f4d358c4f00327b771364",
            "58f862675cad4875bcaa3606a2f64eaf",
            "436a0e9dbfa94fe09eff596ae25c1d9d",
            "df8bf2eb7c6f4575baf964d1d01e8d34",
            "545ebad46ac843dbb1ce6e81e0ffc4d2",
            "53ed23b6eef24d909323ce237a3c47e1",
            "671c57cd016146b3a0edbc3c2a017000",
            "bef99a65eb9940a6be59075aa96e2009",
            "524a7be19927433aaa69fd003299e602",
            "14f20c4971de4ddda88711475b6b9bd5",
            "1a30cd590ab243c497ab230c3da5778c",
            "04d06a30c6c94221ac7e3274d166b0b7",
            "f606efd992c54306bc2aff7d36be6dc0",
            "fde832914c1a4fa28cb1523fc7fa3540",
            "e56cbf8a95324aa683cc8bc56f1486de",
            "2fe94840c48c45618590f085d2896c44",
            "0b9df8ed9c3741c088a3ae6a29c095eb",
            "092a7473129b40fe838b18a57e043ef4",
            "21891f686aba482bb06faf0ec73ee626",
            "4c2835e1f8d644b196e3e392abcd824b",
            "f2ba69850457407689d10bd6c66da3a0",
            "2cf0cc8a6fc44943be75c0df63c0cb63",
            "b0b52b17e2664d7c9fa7534c1069b37b",
            "9740864ba6944e14bb337ab103ef4d61",
            "340d57bd150449058e22de2fcc4a0ae4",
            "4ca43fce06ff4ff684285ca2b0c0c55d",
            "cf55f57cd5f64911ae8b52913b1a9e3d",
            "47ce22f6fc344d769c4935eeda2b9491",
            "193b6503af2a4978a9265a801f6fed24",
            "23e70f2aaae7439a94c750a7b44d93e7",
            "6a662670fa394dc79ab9f1d3176a35d6",
            "4e707c0889dd462cacbba0edd6a312d8",
            "e379efb3b71e45cb80be1861730ddcab",
            "e497394ff6ff4d409a186196e71837cd",
            "9abfd37ac3e544b799ce5a8726a2dc02",
            "bd4bfb0b78424170b23ca0309aa63ca1"
          ]
        },
        "id": "KpnU36OHVp72",
        "outputId": "4ab6a2cf-0804-42e9-c563-018bb1675e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/908 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45974752d2d84dff83b179b1d732caac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0f58cdcacf144298a1df8debc13f717"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "320b3d72d5704117941087f25edd025a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ef4f36e1c2041809672eb5eef8f9848"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/298 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10f5b9fae11b4f7c8dba7ed79df7b6c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df8bf2eb7c6f4575baf964d1d01e8d34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e56cbf8a95324aa683cc8bc56f1486de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ca43fce06ff4ff684285ca2b0c0c55d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Hindi Text: एमिट, एक उच्च प्रभाव एआई शोधकर्ता है, ध्यान में तेज, ड्राइव में आरामदायक है और हमेशा आगे बढ़ता है।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load HF_TOKEN securely set as a secret in Colab\n",
        "HF_TOKEN = userdata.get('dev-token')\n",
        "\n",
        "if HF_TOKEN is None:\n",
        "    print(\"HF_TOKEN secret not found. Please set it in Colab secrets first.\")\n",
        "else:\n",
        "    print(\"HF_TOKEN secret found.\")\n",
        "    login(HF_TOKEN)\n",
        "    try:\n",
        "        # Initialize the Hindi text generation pipeline\n",
        "        model_id = \"CoRover/BharatGPT-3B-Indic\"\n",
        "        hi_lan_gen = pipeline(\"text-generation\", model=model_id, token=HF_TOKEN)\n",
        "\n",
        "        # Check if tokenizer is loaded\n",
        "        if hi_lan_gen.tokenizer is None:\n",
        "            raise ValueError(\"Tokenizer failed to load. Ensure the model is accessible and correctly configured.\")\n",
        "\n",
        "        # English input sentence\n",
        "        english_sentence = \"Amit, is a high impact AI researcher, sharp in focus, relentless in drive and always step ahead.\"\n",
        "\n",
        "        # Create a prompt for translation\n",
        "        prompt = f\"Translate the following English sentence into Hindi: {english_sentence}\"\n",
        "\n",
        "        # Generate the Hindi translation\n",
        "        output = hi_lan_gen(\n",
        "            prompt,\n",
        "            max_length=100,\n",
        "            num_return_sequences=1,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=hi_lan_gen.tokenizer.eos_token_id if hi_lan_gen.tokenizer.eos_token_id is not None else 0\n",
        "        )\n",
        "\n",
        "        # Print the translated text\n",
        "        print(\"Translated Hindi Text:\", output[0]['generated_text'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing pipeline or generating text: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "199aa7bd52974b54acc7e1205ddbbf93",
            "6b5a6bd9ce194ecba1e351a119bebf34",
            "8302389383984fc78b440407a3a6c1a6",
            "467e72828024448bb53b05f1f9c70f44",
            "30697b0e245f4201bc4c5b372486e934",
            "26377a71fbc6493495a193977072239b",
            "b42c06979e034838873ba7a2a23cddf7",
            "d1e1c83a54dd47e1b51fbbf38311b7de",
            "2535b28375b646c7b0734803828d4956",
            "1f744539cf2d492880dbf669a9afcd53",
            "4a7041e521744ce2bdd0949def390f6f"
          ]
        },
        "id": "XetoTV8-X1jp",
        "outputId": "46a7ce24-e2b1-44eb-f7b7-7a2bfa49c87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN secret found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "199aa7bd52974b54acc7e1205ddbbf93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Hindi Text: Translate the following English sentence into Hindi: Amit, is a high impact AI researcher, sharp in focus, relentless in drive and always step ahead.  अमित एक उच्च प्रभाव AI रिसर्चर हैं, तेज़ केंद्रित ध्यान, अहंकारी प्रवासी और हमेशा आगे के चरण में हैं।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the translation pipeline\n",
        "translator = pipeline(\"translation\", model=\"facebook/m2m100_418M\", src_lang=\"en\", tgt_lang=\"hi\")\n",
        "\n",
        "# English input sentence\n",
        "english_sentence = \"Amit, is a high impact AI researcher, sharp in focus, relentless in drive and always step ahead.\"\n",
        "\n",
        "try:\n",
        "    # Perform translation\n",
        "    translated = translator(english_sentence, max_length=100)\n",
        "\n",
        "    # Print the translated text\n",
        "    print(\"Translated Hindi Text:\", translated[0]['translation_text'])\n",
        "except Exception as e:\n",
        "    print(f\"Error during translation: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0gNaMR2YRHH",
        "outputId": "2579b723-9ed0-4e96-f66d-276fe0b2e3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated Hindi Text: एमिट, एक उच्च प्रभाव एआई शोधकर्ता है, ध्यान में तेज, ड्राइव में आरामदायक है और हमेशा आगे बढ़ता है।\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
