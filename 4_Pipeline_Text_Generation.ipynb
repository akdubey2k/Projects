{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: Text generation\n",
        "\n",
        "Now let’s see how to use a **`pipeline`** to generate some text. The main idea here is that you *provide a prompt* and the *model will auto-complete* it by generating the remaining text.\n",
        "\n",
        "This is similar to the **predictive text feature** that is found on many phones. Text generation involves randomness, so it’s normal if you don’t get the same results as shown below."
      ],
      "metadata": {
        "id": "ukWOcNOOxQrJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hz2vfyQuxBGs"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410,
          "referenced_widgets": [
            "a5d2035396f84195b3ba8f2f78f6e910",
            "9bc0d8f24672483483fe365ef42ada5b",
            "cea478e4beb743f7b72235e3c343e37b",
            "31007a786b7e443d8be3cd7261289011",
            "db493be04f0c442c9f8e0c689a51226d",
            "01a0f12cea1d47a8b9a02b2d5f66d1fb",
            "84a9868bef824cc99f48f6ad22368230",
            "ffe63eb471f247728f14a6c7cc2d287d",
            "917b271543a64ec7b1cee32baad21cdc",
            "3524a092a72f4f30b04f0dc86cd4c755",
            "5acf828c091742b2b3f388e400003875",
            "7bee4a4d173c43e4bc428a68bebd7800",
            "7dc5bbe11cdc4ff28d6031c02c149d73",
            "9a00eada23a242abadddd0905a8d2ec2",
            "3274c416bf134acc809c7374d5ea65fe",
            "aca35ceb2f884b569efcdde36dd11f21",
            "dc8e1c0651164808af61a64998fe66b1",
            "5a7056c19546478ca7cf6730e78744c6",
            "b1a3615f05fb4c4d8f872626b0a3ff3d",
            "c6e80b668c824729bd8e2413d595cf08",
            "e4717ea0c7be49628d61b1c7de25c268",
            "d91b485695e24994a8c96d5ce9718af2",
            "3746db46472a49ce82b585a007796ad5",
            "c75f810caec04175a66781fffaf304e5",
            "24c6a304e3364ce894ab34ac81988ddd",
            "599a02a5e53d4e09af53ae877af18a2c",
            "4906fe3d92304164a1c53fea68715ef4",
            "014e1bd98f7645f4bbba158f2e58720b",
            "3f2af3d6271a44d998434797d7dd0334",
            "cce8443bd8fb4c72b11862c86f48ac48",
            "27ff96d2786c43be9ec26247596a3fdd",
            "64eef1a23ab041c78cf6bc9d95394518",
            "2ded39885b744d43877bfdaf5e09aa13",
            "0be08ee4d12143299f53e2899e4fd638",
            "290351dd78dd43328f18937a698bc362",
            "49d4d91fea054de8a302483137658b3a",
            "4bfb822552e34c7681aa8592f845213f",
            "7a82132d15db48568457e25349155489",
            "f030ca5650e840a5b0dd1075c65af669",
            "7f9b18e3c8fb44b5adeec55e66b858a4",
            "adbc9e9aa1f84c0f97c85dbd5378aedc",
            "4446b9ff6f06452e9e577a22b93858c1",
            "47f81898a1884d8d86801f075f837ada",
            "3b3ce0a51a814732be57d46758c9c472",
            "dae0a1e9e8a042c5b0641b6ae53bb27f",
            "12d892060b5d472c863a5fb0de9913e0",
            "eb87ce7399394ab0b95e0d17206c1be5",
            "4b78ca0be91b42f2aa304c6b4d2fab3e",
            "e28e8b35680d46ab860cc29fbcee1ea2",
            "85ee86af75c144ff97fdd1df2226bf0a",
            "c20c863e93814631931417cc68245197",
            "3c6ac44182de461cb488949232df5003",
            "65973532cc054f8582334371eda827c1",
            "de08455445db46a8888a4db16f8943fa",
            "80731036edb94678ae3921daaec5c0af",
            "6bfaa62c64f640dabfcd6631cc213419",
            "27b0e0abdb2644d8bc65867513d41ea0",
            "7aee17f04c2f4fb5be5db0e30ea299c0",
            "7592fdb248f94487a7382e19c997c39f",
            "87cd9386441e46a88e1569ff2efb8942",
            "692a33dff8a14526a86517ec4af788cb",
            "18cea70d8f034ba7abb62540be81c3fe",
            "6577014131b547378dc8a5006462d70a",
            "f2392ca4f3244b108f1ce22ad880282d",
            "f86a564a8951480684361f9d5297ad3c",
            "5d8d2d8520d9482dacf2d6df5c28100c",
            "60d47e85941245ee9aca6e7ea8081c22",
            "237b64293e9142849be30ac5d38d921b",
            "7eec0bffef5e4c318a120d948f6b294b",
            "c8b9f19dd7e54a2db426528752f410ca",
            "d52928b5185f40bca0fe430296f4d5fc",
            "b8eb66eb0f244f519805eee8fa75fd3a",
            "cfcdd88d450b43ae823ea0b89464f8c5",
            "6211e456d368402ab23074385ecd92d7",
            "17bb9e23b22f41dab4815f70ef8e4cfa",
            "db0fd0b52d9743f3987dd09f02311c56",
            "2ce2f45b74a54b879e9ea97dc0dd17f0"
          ]
        },
        "id": "RILmDCUjz0pA",
        "outputId": "126e5cda-7f3b-48d5-94c1-9b9ee5407d63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5d2035396f84195b3ba8f2f78f6e910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bee4a4d173c43e4bc428a68bebd7800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3746db46472a49ce82b585a007796ad5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0be08ee4d12143299f53e2899e4fd638"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae0a1e9e8a042c5b0641b6ae53bb27f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bfaa62c64f640dabfcd6631cc213419"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60d47e85941245ee9aca6e7ea8081c22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator([\"Amit, is a high impact leader\", 'sharp in focus', \"relentless in drive and always step ahead in AI reasearcher journey\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vENltmwz76Q",
        "outputId": "580be28a-9ae8-46d3-85cc-c6bdf7506734"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'generated_text': 'Amit, is a high impact leader in the field of environmental environmental impact modeling. His publications include the 2010 report, The Endangered Species of the Pine Tree (Pine Tree, 2011), and the 2011 issue of the journal PNAS. He is a co-author on the current chapter, \"Shared Responsibility for a Changing Climate,\" and is a member of the Advisory Board of the National Academy of Sciences. He has authored several books, including The Endangered Species of the Pine Tree (2013).'}],\n",
              " [{'generated_text': \"sharp in focus, and will be able to offer a wide range of options.\\n\\nFor the full list of changes, visit our wiki.\\n\\nFor an overview of the changes, see on-line changes.\\n\\nWe'll be working with all the community and the media to determine what features are needed. Keep an eye out for a release announcement coming soon.\\n\\nFor more information, see the wiki.\\n\\nWant to learn more about what's new with the SDK? Check out our SDK guide for getting started.\\n\\nAlso see: For a more complete list of changes, see our wiki.\\n\\nFor more information on the open source community, see the open source community wiki.\\n\\nFor a complete list of changes, see the wiki.\\n\\nThe new SDK should be ready for the next major release.\\n\\nFor a complete list of changes, see our wiki.\\n\\nThe new APIs will be open source, so it's possible to use them for your own projects with a single call.\\n\\nThe new SDK will come with a number of new APIs, including:\\n\\nFeature-rich API that allows you to create and control new features without having to maintain them yourself.\\n\\nAPI that allows you to create and control new features\"}],\n",
              " [{'generated_text': 'relentless in drive and always step ahead in AI reasearcher journey or work.\\n\\n\"You can go about your business, you can go about your business, but if that\\'s you don\\'t have a clear path to your goal. You have to come up with your own path,\" he says.\\n\\nThis is a key point not only for AI researchers, but for all of us who are involved with AI projects and are working on a new technology. The rise of AI is already affecting our lives and our careers. \"It affects the way we think and we can\\'t have clear goals, you can\\'t have clear goals if you don\\'t have a clear path,\" says K.C. Huygens, a senior researcher at the Singularity University in Singapore.\\n\\nAI is already affecting the way we think and we can\\'t have clear goals, you can\\'t have clear goals if you don\\'t have a clear path.\\n\\nEven though AI is already affecting our lives, it\\'s becoming increasingly necessary for us to look at our own lives at the same time. \"We don\\'t have a clear path to our goal,\" says Huygens.\\n\\nWe need to start thinking about our own lives and how we will do them.\\n\\n\"We\\'re going to have to start thinking about our own'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can control how many different sequences are generated with the argument **`num_return_sequences`** and the total length of the output text with the argument **`max_length`**."
      ],
      "metadata": {
        "id": "SAO1cio50rlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using any model from the Hub in a pipeline\n",
        "\n",
        "In the previous examples you used the default model for the task at hand, but you can also choose a particular model from the Hub to use in a **pipeline** for a specific task — say, **text generation**. Go to the HF's [Model Hub](https://huggingface.co/models?pipeline_tag=text-generation) and choose what best suits you."
      ],
      "metadata": {
        "id": "W5aoxjCh2Vr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"HuggingFaceTB/SmolLM2-360M\")"
      ],
      "metadata": {
        "id": "MIVew_bj3c8N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310,
          "referenced_widgets": [
            "06979e4a26434dc9a8ff4c7af2b6aee3",
            "7ba995aebb7e41dea67ddef377e274e7",
            "7cb91c1833e143ff86e2e6beb5953155",
            "d752f74d39054d30a5c742a7fc4a5713",
            "bb2feee735634c99a3ebde581307d99d",
            "5092f467092541a4b97c083440678d21",
            "66a28294bbbd4473a7eb55a89d6fcba7",
            "8ebb32743d2c427390f220492428ab24",
            "81ab278a9589445caacaf63926f5d8ba",
            "a354ca4bbe964960853cf34ef89271fa",
            "76005b13cfe540c685f216c19b25167e",
            "2f839f73da184a58a6611c8340a5dabf",
            "71ad00ed248344998d74611dcfe28eee",
            "663b248cfeec441992e2343448d3c654",
            "d4181005e0f84e468d62acccdb4f7e29",
            "e98751ce5be0453faa4f47ae123a5b0e",
            "3b3ebe04364a4648925f235c665808e9",
            "84376a9629ff450cba901abbe235b336",
            "fdf06c03cb7b4345bdcaba2a50bf2738",
            "6dadbd48c7e14fbebc087578454f6d88",
            "691f0a42e6824efa9ebeef40bc1b23d0",
            "64afe211da504248a97a42f4dbbc5ca0",
            "1613622992eb4040b75cb069d12f5425",
            "c659ac9f4cfa46b49a56c434462ca53a",
            "3f9e2f650c1e4c83a9ef0c7634c4b4b2",
            "40caf75c0fae43a3b9fdff8a4e2466c4",
            "ebb626522f70486c9873a312274036d1",
            "75cfa32b9d8345d4b4d058d2ace593c3",
            "12110dff0570444db7450b19a5eaa994",
            "2a7cdb126a1e4ddb8817dffa1870d0f8",
            "99b6198564ce49e0863da2755cf0606e",
            "357860cc8b2a45c8a01fab70d28e315d",
            "352e63bf167b4991820e70bddc6a0acf",
            "d254abf88413430b8e6b9f14fea54bc7",
            "03942a6fb3c94a22a50ad5904a292b27",
            "9fc0e5e5c6df4d2b83780c4595bc0a65",
            "dd31067b7ddc48da9ce40ead5ddb64a6",
            "492a8533fe7143599dd0cff1412ba6b5",
            "c5cb52cbffef40749967cd9ab97c9898",
            "8d92895e767a4b3fbd153b85fbe55e59",
            "c52c411f89e64c0aafb5803db51d55a3",
            "551128ca0c3d453e83d018c681519a39",
            "8ade6479b7204a24b69c2324c176efaa",
            "39c5edaea8134e369ff18f8836044e08",
            "66b340b0593a4e439d800db42472a1c0",
            "3afa4bed22e54566980277536bc54fd8",
            "a660f5f098b446caae2347a9e0b20943",
            "4b6d809df66645b987144c505707449e",
            "9cfe93207bb24157ab45a1ace41fce91",
            "54f042088fab49f0911287b790cf5bf7",
            "dd80bc3661444fa093459e91f7a319ae",
            "44ffc9065b0445f8b449adbe3dd77798",
            "2207ce0b1ede4365be869417fd40aed1",
            "98226ea4bc144f5c8179f02fec9bc21d",
            "b969e9cd803c447f9eaecdd24dc8812b",
            "9b702d68c1a54d51a32e51be062e5886",
            "8fda618464ae4b29bd82fb96bdcb81f7",
            "e9555db1434b44a4afd1d6080641aa9d",
            "877388ae19a74c90b0530242f0f6559e",
            "c9232f800e0547f985af036910f05818",
            "2f4f61d2efba429fafe52f3a177b1fa1",
            "d7a0dd7d55fa430f80b488a9a656be58",
            "aea6d8975dda422682154d3238e2358a",
            "d5a8b0a5b2e848e997c99ea709e30bd5",
            "31510bb5c2cc4596a72b1ccf5854feef",
            "8a23a7a759b44300b8fefccd39cce706",
            "92a3fe7fec97408bb2a2f2dfcad30a0a",
            "4dba5e30d44547ec98ccd6a30b448af2",
            "2c7d3bb4e9ee421c8d4824e2c8231255",
            "c4527f64e71948f3ad7a4f6a62cbd6fe",
            "2f47a15bbb2d42b1aef395677b074f1b",
            "f37c87946d984ef79bb3fa12eed8bc79",
            "0f89cae8e7ca49cebb61eb631d0cd969",
            "7c3951386c4845b9b112fed2021a7c10",
            "892f8e3251144d39a9c7599b8d72ed98",
            "0a1261ce73f048e09c36c9b730e22aed",
            "dcfc2c7be3b34473a74800a6a1c0d7ff",
            "e813119ece764677ad4a0354adc82ba2",
            "ce76c5b24bfc46eaa79d0a226a5d50fe",
            "e9a1bac7631f4e7b89bfb01cb58eed90",
            "8ccbf2b46c4c4ed3882dde03f2cbd8f7",
            "121fe0e12c514280be3a8d9b6c42555f",
            "8280dc6c40074d389e8898d65ae11b1a",
            "a03002a04fa14d4585be26eae58ad4b5",
            "0eaf4db7c5344fa7b35b4698e93f5540",
            "28c461b722fb4901a88bc9bda8784176",
            "db070528fb584d8dae992a08366d8484",
            "172b6f64f6f14f699f85089499d65596"
          ]
        },
        "outputId": "47863565-8ba9-4133-c8b2-27914c10df63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06979e4a26434dc9a8ff4c7af2b6aee3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/724M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f839f73da184a58a6611c8340a5dabf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1613622992eb4040b75cb069d12f5425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d254abf88413430b8e6b9f14fea54bc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66b340b0593a4e439d800db42472a1c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b702d68c1a54d51a32e51be062e5886"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92a3fe7fec97408bb2a2f2dfcad30a0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/831 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e813119ece764677ad4a0354adc82ba2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"Amit, is a high impact AI reasearcher, sharp in focus, relentless in drive and always step ahead.\",\n",
        "  max_length=30,\n",
        "  num_return_sequences=1,\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9QJzvws3F0v",
        "outputId": "c0b9dfd2-b033-48bb-a94c-91ade1803237"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Amit, is a high impact AI reasearcher, sharp in focus, relentless in drive and always step ahead.\\n\\nHe is a prolific author of papers on AI, and also a prolific speaker who covers a wide range of AI topics and has been awarded a number of prestigious awards. He has authored over 100 research papers on AI and has been an active contributor to the AI community since 2014. Amit is an avid reader and enjoys reading the latest research papers on AI, and has been a regular contributor to the\\xa0TechCrunch\\xa0and\\xa0TechCrunch Disrupt\\xa0for the last 10 years.\\n\\nAmit was the first AI researcher to\\xa0break into the mainstream media and publish his ideas in the mainstream media, which made him a very popular person in the AI community. He is also a regular keynote speaker at conferences and is a regular guest speaker at AI conferences across the world.\\n\\nHe is an avid reader, and enjoys reading the latest research papers on AI. He also enjoys programming and enjoys writing for his blog,\\xa0The AI Blog.\\n\\nAmit’s favorite books include:\\xa0“The Art of Computer Programming”\\xa0by Donald Knuth,\\xa0“The Art of Computer Programming”\\xa0by Donald Knuth,\\xa0“The Art of Computer Programming”\\xa0by Donald Knuth,\\xa0'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HF pipeline for text generation\n",
        "* The main idea here is that you provide a **prompt** and the **model** will *auto-complete it by generating the remaining text*.\n",
        "* This is similar to the predictive text feature that is found on many phones.\n",
        "\n",
        "* You can control how many different sequences are generated with the argument **`num_return_sequences`** and the total length of the output text with the **`argument max_length`**."
      ],
      "metadata": {
        "id": "ZgWS9myiBrxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbstripout\n",
        "!nbstripout --install"
      ],
      "metadata": {
        "id": "WUEIvDcBB_ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "751d0d95-d228-477f-90cb-056f508b43bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nbstripout\n",
            "  Downloading nbstripout-0.8.1-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from nbstripout) (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.8.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n",
            "Downloading nbstripout-0.8.1-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: nbstripout\n",
            "Successfully installed nbstripout-0.8.1\n",
            "fatal: --local can only be used inside a git repository\n",
            "Installation failed: not a git repository!\n"
          ]
        }
      ]
    }
  ]
}
