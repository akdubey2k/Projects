{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# First, install transformers if not already done\n",
        "!pip install -q transformers huggingface_hub"
      ],
      "metadata": {
        "id": "ePJbwB-tdgCm"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0EKd6NVTX8Fr"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "# import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load HF_TOKEN securely set as a secret in Colab\n",
        "# HF_TOKEN = os.getenv(\"dev-token\")\n",
        "HF_TOKEN = userdata.get('dev-token')"
      ],
      "metadata": {
        "id": "I8N-U44YeZkU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        " is an advanced, pre-trained AI model from **Hugging Face** that performs\n",
        " - sentiment analysis on English text, particularly tweets.\n",
        "\n",
        " It classifies text into three categories—**Negative, Neutral, and Positive**—by adapting a **RoBERTa-base transformer model** with a massive dataset of Twitter data and fine-tuning it on the TweetEval benchmark.\n",
        "\n",
        " This makes it efficient and effective for understanding public opinion and analyzing the emotions within social media content."
      ],
      "metadata": {
        "id": "IqFA2OHSo3Hl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if HF_TOKEN is None:\n",
        "  print(\"HF_TOKEN secret not found. Please set it in Colab secrets first.\")\n",
        "else:\n",
        "  print(\"HF_TOKEN secret found.\")\n",
        "\n",
        "  # Authenticate to Hugging Face Hub using the retrieved token\n",
        "  login(HF_TOKEN)\n",
        "\n",
        "  # Specify the model name you want to use for sentiment analysis\n",
        "  model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "\n",
        "  # Supply model name to the pipeline explicitly\n",
        "  classifier = pipeline(\"sentiment-analysis\", model=model_name)\n",
        "\n",
        "  text_dataset = [\"I am a world's best leader and my organization is worth of 200000000 billion usd\",\"Intel is looser due to higher management decisions.\"]\n",
        "\n",
        "  results = classifier(text_dataset)\n",
        "\n",
        "  for text, result in zip(text_dataset, results):\n",
        "    print(f\"Text: {text}\\nSentiment: {result['label']}, Score: {result['score']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdIrON66ei1e",
        "outputId": "c2fee489-e3c0-446f-fc7b-526dfc57e22b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN secret found.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I am a world's best leader and my organization is worth of 200000000 billion usd\n",
            "Sentiment: positive, Score: 0.9580757021903992\n",
            "\n",
            "Text: Intel is looser due to higher management decisions.\n",
            "Sentiment: negative, Score: 0.7128911018371582\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Key reasons:\n",
        "1. Trained and fine-tuned on large **English Twitter\n",
        "datasets** capturing nuanced language use.\n",
        "2. Optimized for **sentiment classification** *(positive, negative, neutral)*.\n",
        "3. Lightweight yet powerful enough for real-time applications.\n",
        "4. Widely used and supported in **Hugging Face pipelines.**"
      ],
      "metadata": {
        "id": "BwuZCDBDjW6c"
      }
    }
  ]
}